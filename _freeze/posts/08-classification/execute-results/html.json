{
  "hash": "41450487a142ec519f8bfc1a33dcf593",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"8: Classification Analysis for Fraud Detection\"\ndate: today\nexecute: \n  eval: false\n  message: false\n  warning: false\n---\n\n## Executive Summary\n\n*Write a 2-3 sentence summary of your classification analysis and the fraud detection model's performance. Complete this section after finishing the assignment.*\n\n---\n\n## Introduction\n\nAs an accounting professional implementing fraud detection systems, you need to build models that can automatically identify potentially fraudulent transactions. Classification analysis helps auditors:\n\n- Predict whether transactions are fraudulent or legitimate\n- Prioritize high-risk transactions for investigation\n- Reduce manual review workload\n- Improve fraud detection consistency\n\nIn this blog post, you will:\n\n- Build a decision tree model for fraud detection\n- Evaluate model performance with business metrics\n- Analyze which factors best predict fraud\n- Recommend implementation strategies for the fraud detection system\n\n## Setup and Load Libraries\n\n### Required Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages we need - matching the slides\nlibrary(tidyverse)    # For data manipulation\nlibrary(tidymodels)   # For classification modeling\nlibrary(scales)       # For formatting numbers\nlibrary(gt)           # For nice tables\nlibrary(rpart.plot)   # For visualizing decision trees\nlibrary(vip)          # For variable importance\n\n# Set preferences\ntheme_set(theme_minimal())  # Clean plots\noptions(scipen = 999)       # No scientific notation\nset.seed(2027)              # Reproducible results\n```\n:::\n\n\n### Load and Explore the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the fraud detection data\nfraud_data  <- read_rds(\"data/08-assignment-fraud_data.rds\")\n# TODO: fix path after loaded on web\n\n# Display structure of the data\nglimpse(fraud_data)\n\n\n# Check the fraud rate\nfraud_data |>\n  count(_____) |>  # Count by fraud status\n  mutate(percentage = percent(n / sum(n))) |>\n  gt() |>\n  tab_header(title = \"Distribution of Fraud vs Legitimate Transactions\") \n```\n:::\n\n\n## Initial Data Exploration\n\n### Transaction Amount Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Analyze amount patterns\namount_summary <- fraud_data |>\n  group_by(_____) |>  # Group by fraud status\n  summarize(\n    count = n(),\n    avg_amount = mean(_____),\n    median_amount = median(_____),\n    max_amount = max(_____),\n    round_amounts = sum(_____),  # Count round amounts\n    .groups = \"drop\"\n  )\n\nno_legit  <- amount_summary |>filter(fraud == \"Legitimate\") |>pull(count)\nno_fraud  <- amount_summary |>filter(fraud == \"Fraudulent\") |>pull(count)\n\navg_fraud_amt  <- amount_summary |> filter(fraud == \"Fraudulent\") |> pull(avg_amount)\n\n# Display summary using gt\namount_summary |>\n  gt() |>\n  fmt_currency(columns = c(_____, _____, _____), decimals = 0)\n\n# Visualize amount distribution\nggplot(fraud_data, aes(x = _____, fill = _____)) +\n  geom_histogram(bins = 30, position = \"dodge\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_fill_manual(values = c(\"Legitimate\" = \"steelblue\", \"Fraudulent\" = \"red\")) +\n  labs(\n    title = \"Transaction Amount Distribution by Fraud Status\",\n    x = \"Amount\",\n    y = \"Count\",\n    fill = NULL\n  )\n```\n:::\n\n\n### Risk Factor Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Analyze risk factors\nrisk_patterns <- fraud_data |>\n  group_by(_____) |>  # Group by fraud status\n  summarize(\n    # Vendor patterns\n    new_vendors = sum(vendor_type == \"New\"),\n    avg_vendor_age = mean(_____),\n    \n    # Timing patterns\n    weekend_trans = sum(_____),\n    after_hours = sum(_____),\n    rushed_approvals = sum(is_rushed),\n    \n    # Documentation\n    poor_documentation = sum(_____),\n    avg_doc_score = mean(_____),\n    \n    .groups = \"drop\"\n  ) |>\n  # Calculate percentages\n  mutate(\n    new_vendor_pct = percent(new_vendors / c(no_legit, no_fraud), accuracy = 1),\n    weekend_pct = percent(weekend_trans / c(no_legit, no_fraud), accuracy =1),\n    after_hours_pct = percent(after_hours / c(no_legit, no_fraud), accuracy =1),\n    rushed_pct = percent(rushed_approvals / c(no_legit, no_fraud), accuracy =1)\n  )\n\n# Display risk patterns\nrisk_patterns |>\n  select(fraud, new_vendor_pct, avg_vendor_age, weekend_pct, after_hours_pct, rushed_pct, poor_documentation,  avg_doc_score) |>\n  gt() |>\n  tab_header(title = \"Risk Factor Analysis by Fraud Status\") |>\n  fmt_number(columns = c(avg_vendor_age, avg_doc_score), decimals = 1)\n```\n:::\n\n\n## Data Preparation\n\n### Split Data for Training and Testing\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Split data into training (75%) and testing (25%) sets\nfraud_split <- initial_split(fraud_data, prop = _____, strata = _____)\n\n# Create training and testing datasets\nfraud_train <- training(_____)\nfraud_test <- testing(_____)\n\n# Check the distribution in each set\nfraud_train |>\n  count(fraud) |>\n  mutate(percentage = percent(n / sum(n)))\n\nfraud_test |>\n  count(fraud) |>\n  mutate(percentage = percent(n / sum(n)))\n```\n:::\n\n\n## Building a Decision Tree Model\n\n### Step 1: Create Recipe and Model Specification\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a recipe (preprocessing steps)\nfraud_recipe <- recipe(fraud ~ amount + vendor_type + is_weekend + is_after_hours + \n                      documentation_score + is_rushed + vendor_age_days,\n                      data = _____) |>\n  step_normalize(_____, _____)  # Normalize numeric features\n\n# Specify the decision tree model\ntree_spec <- decision_tree(\n  tree_depth = _____,    # Maximum depth (try 4)\n  min_n = _____          # Minimum observations per node (try 10)\n) |>\n  set_engine(\"rpart\") |>\n  set_mode(\"_____\")      # What are we predicting?\n\n# Create workflow\ntree_workflow <- workflow() |>\n  add_recipe(_____) |>\n  add_model(_____)\n```\n:::\n\n\n### Step 2: Fit the Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit the model on training data\nfraud_tree_fit <- tree_workflow |>\n  fit(data = _____)\n\n# Display the fitted model\nfraud_tree_fit\n```\n:::\n\n\n### Step 3: Visualize the Decision Tree\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract the decision tree for visualization\ntree_for_plot <- fraud_tree_fit |>\n  extract_fit_engine()\n\n# Create an interpretable plot\nrpart.plot(tree_for_plot,\n          type = 4,\n          box.palette = \"BuRd\",\n          main = \"Fraud Detection Decision Tree\",\n          sub = \"Each box shows: Predicted class, probability of fraud, % of observations\")\n```\n:::\n\n\n## Model Evaluation\n\n### Step 4: Make Predictions and Create Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make predictions on test set\ntest_predictions <- augment(_____, _____)\n\n# Create confusion matrix\nconf_matrix <- test_predictions |>\n  conf_mat(truth = _____, estimate = _____)\n\n# Visualize confusion matrix\nautoplot(conf_matrix, type = \"heatmap\") +\n  labs(title = \"Confusion Matrix\",\n       subtitle = \"How well did we predict fraud?\")\n```\n:::\n\n\n### Step 5: Calculate Performance Metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define metrics we want\nfraud_metrics <- metric_set(accuracy, sensitivity, specificity, precision)\n\n# Calculate metrics\nmodel_metrics <- test_predictions |>\n  fraud_metrics(truth = _____, estimate = _____, event_level = \"second\") |>\n  select(.metric, .estimate) |>\n  mutate(.estimate = percent(.estimate))\n\n# Display metrics\nmodel_metrics |>\n  gt() |>\n  tab_header(title = \"Model Performance Metrics\")\n```\n:::\n\n\n## Variable Importance Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract variable importance\ntree_importance <- fraud_tree_fit |>\n  extract_fit_parsnip() |>\n  vip::vi() |>\n  mutate(\n    Variable = case_when(\n      Variable == \"amount\" ~ \"Transaction Amount\",\n      Variable == \"vendor_type\" ~ \"Vendor Type\",\n      Variable == \"is_weekend\" ~ \"Weekend Transaction\",\n      Variable == \"documentation_score\" ~ \"Documentation Score\",\n      Variable == \"is_rushed\" ~ \"Rushed Approval\",\n      TRUE ~ Variable\n    )\n  )\n\n# Display importance\ntree_importance |>\n  gt() |>\n  tab_header(title = \"Variable Importance for Fraud Detection\") |>\n  fmt_number(columns = Importance, decimals = 1)\n\n# Create importance plot\ntree_importance |>\n  mutate(Variable = fct_reorder(Variable, Importance)) |>\n  ggplot(aes(x = Importance, y = Variable)) +\n  geom_col(fill = \"steelblue\") +\n  labs(\n    title = \"Which Features Best Predict Fraud?\",\n    x = \"Importance Score\",\n    y = NULL\n  )\n```\n:::\n\n\n## Business Impact Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate business metrics\nbusiness_impact <- test_predictions |>\n  mutate(\n    # Define risk levels based on probability\n    risk_level = case_when(\n      .pred_Fraudulent >= 0.7 ~ \"High Risk\",\n      .pred_Fraudulent >= 0.4 ~ \"Medium Risk\",\n      TRUE ~ \"Low Risk\"\n    )\n  ) |>\n  summarize(\n    # Detection rates\n    total_fraud = sum(fraud == \"Fraudulent\"),\n    fraud_detected = sum(fraud == \"Fraudulent\" & .pred_class == \"Fraudulent\"),\n    detection_rate = fraud_detected / total_fraud,\n    \n    # False positive impact\n    false_positives = sum(fraud == \"Legitimate\" & .pred_class == \"Fraudulent\"),\n    false_positive_rate = false_positives / sum(fraud == \"Legitimate\"),\n    \n    # Workload analysis\n    high_risk_count = sum(risk_level == \"High Risk\"),\n    investigation_rate = high_risk_count / n()\n  )\n\n# Display business metrics\nbusiness_impact |>\n  pivot_longer(everything(), names_to = \"Metric\", values_to = \"Value\") |>\n  gt() |>\n  tab_header(title = \"Business Impact Metrics\") \n```\n:::\n\n\n## Implementation Recommendations\n\nBased on your analysis, complete these recommendations:\n\n1. **Model Performance**: The decision tree achieved _____% accuracy with _____% sensitivity (fraud detection rate).\n\n2. **Key Fraud Indicators**: The top three predictors of fraud were:\n   - _____: (Importance score: _____)\n   - _____: (Importance score: _____)\n\n3. **Investigation Strategy**: \n   - Focus on transactions with fraud probability > _____% \n   - This would require investigating _____% of transactions\n   - Expected to catch _____% of actual fraud\n\n4. **Control Improvements**:\n   - Strengthen controls around _____ (highest importance variable)\n   - Implement automated flags for _____\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}