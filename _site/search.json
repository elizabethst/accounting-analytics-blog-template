[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Your name is a student at Sonoma State University. Her concentration is accounting, and she plans to become a certified public accountant (CPA)."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nSonoma State University | Rohnert Park, CA BS in Business | start date - grad date"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nAccounting Firm | Accounting Intern | June 2025 - August 2025\nAnother Firm | Customer Service | Jan 2025 - June 2025"
  },
  {
    "objectID": "posts/02-introduction.html",
    "href": "posts/02-introduction.html",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "",
    "text": "Write a 2-3 sentence summary of what you learned about using R for accounting calculations after completing this assignment."
  },
  {
    "objectID": "posts/02-introduction.html#executive-summary",
    "href": "posts/02-introduction.html#executive-summary",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "",
    "text": "Write a 2-3 sentence summary of what you learned about using R for accounting calculations after completing this assignment."
  },
  {
    "objectID": "posts/02-introduction.html#introduction",
    "href": "posts/02-introduction.html#introduction",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "Introduction",
    "text": "Introduction\nR offers powerful advantages:\n\nReproducibility: Every calculation is documented in code\nScalability: Handle thousands of transactions effortlessly\n\nAutomation: Repeat analyses with new data instantly\n\nIn this blog post, I’ll demonstrate how to: - Use R as a financial calculator - Create organized data structures for accounting information - Build depreciation schedules - Analyze financial performance"
  },
  {
    "objectID": "posts/02-introduction.html#setup-and-load-libraries",
    "href": "posts/02-introduction.html#setup-and-load-libraries",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "Setup and Load Libraries",
    "text": "Setup and Load Libraries\n\nRequired Libraries\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation\nlibrary(scales)     # For formatting numbers as currency and percentages"
  },
  {
    "objectID": "posts/02-introduction.html#r-as-your-financial-calculator",
    "href": "posts/02-introduction.html#r-as-your-financial-calculator",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "R as Your Financial Calculator",
    "text": "R as Your Financial Calculator\n\nPresent Value Calculation\nLet’s start with a fundamental finance calculation - present value. If you expect to receive $25,000 in 3 years and the annual interest rate is 4.5%, what is that worth today?\n\n# Set up the variables\nfuture_value &lt;- 25000  \nannual_rate &lt;- 0.045   \nyears &lt;- 3             \n\n# Calculate present value using the formula: PV = FV / (1 + r)^n\npresent_value &lt;- _____ / (1 + _____)^_____\n\n# Display the result\npresent_value\n\n# Display with currency formatting\ndollar(present_value)\n\n\n\nFinancial Ratios\nNow let’s calculate some key financial ratios that help assess company health:\n\n# Current Ratio = Current Assets / Current Liabilities\ncurrent_assets &lt;- 120000\ncurrent_liabilities &lt;- 80000\ncurrent_ratio &lt;- _____ / _____\n\n# Display the current ratio\ncurrent_ratio\n\n# Check if it meets the benchmark of 2.0\nmeets_benchmark &lt;- current_ratio &gt;= _____\nmeets_benchmark\n\n# Quick Ratio = (Current Assets - Inventory) / Current Liabilities\ninventory &lt;- 35000\nquick_ratio &lt;- (_____ - _____) / _____\nquick_ratio"
  },
  {
    "objectID": "posts/02-introduction.html#creating-financial-data-structures",
    "href": "posts/02-introduction.html#creating-financial-data-structures",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "Creating Financial Data Structures",
    "text": "Creating Financial Data Structures\nChart of Accounts Let’s create a simple chart of accounts using a data frame:\n\n# Create chart of accounts using tribble (an easy way to create small data frames)\nchart_of_accounts &lt;- tribble(\n  ~account_code, ~account_name,         ~account_type, ~balance,\n  1001,          \"Cash\",                \"Asset\",        25000,\n  1002,          \"Accounts Receivable\", \"Asset\",        18500,\n  1003,          \"Inventory\",           \"Asset\",        32000,\n  2001,          \"Accounts Payable\",    \"_____\",        15000,  # Fill in account type\n  3001,          \"Owner's Equity\",      \"_____\",        60500   # Fill in account type\n)\n\n# View the chart of accounts\nchart_of_accounts"
  },
  {
    "objectID": "posts/02-introduction.html#verify-the-accounting-equation",
    "href": "posts/02-introduction.html#verify-the-accounting-equation",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "Verify the Accounting Equation",
    "text": "Verify the Accounting Equation\nLet’s check if our accounting equation balances (Assets = Liabilities + Equity):\n\n# Calculate totals by account type\naccount_summary &lt;- chart_of_accounts |&gt;\n  group_by(_____) |&gt;  # Group by account_type\n  summarise(total = sum(_____))  # Sum the balances\n\n# View the summary\naccount_summary\n\n# Check if Assets = Liabilities + Equity\n# Hint: You'll need to extract the totals for each account type"
  },
  {
    "objectID": "posts/02-introduction.html#monthly-financial-analysis",
    "href": "posts/02-introduction.html#monthly-financial-analysis",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "Monthly Financial Analysis",
    "text": "Monthly Financial Analysis\nCreating Monthly P&L Data\nLet’s create and analyze profit & loss data for the first quarter:\n\n# Create monthly P&L data\nmonthly_pnl &lt;- tribble(\n  ~month,      ~revenue, ~expenses,\n  \"January\",    65000,    48000,\n  \"February\",   72000,    52000,\n  \"March\",      68000,    49000\n)\n\n# Add calculated columns\nmonthly_analysis &lt;- monthly_pnl |&gt;\n  mutate(\n    net_income = _____ - _____,  # Calculate net income\n    profit_margin = _____ / _____  # Calculate profit margin\n  )\n\n# View the analysis\nmonthly_analysis\n\n\nQuarterly Summary\nNow let’s create a quarterly summary:\n\n# Calculate quarterly totals\nquarterly_summary &lt;- monthly_analysis |&gt;\n  summarise(\n    total_revenue = sum(_____),\n    total_expenses = sum(_____),\n    total_net_income = sum(_____),\n    avg_profit_margin = mean(_____)\n  )\n\n# View quarterly summary\nquarterly_summary\n\n# Format the profit margin as a percentage\npercent(quarterly_summary$avg_profit_margin)"
  },
  {
    "objectID": "posts/02-introduction.html#depreciation-schedule",
    "href": "posts/02-introduction.html#depreciation-schedule",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "Depreciation Schedule",
    "text": "Depreciation Schedule\n\nStraight-Line Depreciation\nLet’s create a depreciation schedule for equipment:\n\n# Equipment details\nequipment_cost &lt;- 75000\nsalvage_value &lt;- 5000\nuseful_life &lt;- 7\n\n# Calculate annual depreciation\nannual_depreciation &lt;- (_____ - _____) / _____\nannual_depreciation\n\n\n\nComplete Depreciation Schedule\n\n# Create the full depreciation schedule\ndepreciation_schedule &lt;- tibble(\n  year = 1:_____  # Create years 1 through useful_life\n) |&gt;\n  mutate(\n    annual_depreciation = _____,  # Same amount each year for straight-line\n    accumulated_depreciation = _____ * year,  # Cumulative depreciation\n    book_value = _____ - _____  # Cost minus accumulated depreciation\n  )\n\n# View the schedule\ndepreciation_schedule\n\n# What's the book value at the end of year 5?\nyear_5_value &lt;- depreciation_schedule |&gt;\n  filter(year == 5) |&gt;\n  pull(book_value)\n\ndollar(year_5_value)"
  },
  {
    "objectID": "posts/02-introduction.html#key-findings-and-reflections",
    "href": "posts/02-introduction.html#key-findings-and-reflections",
    "title": "2 - Introduction to Accounting Analytics",
    "section": "Key Findings and Reflections",
    "text": "Key Findings and Reflections\nSummary of Calculations Based on the analyses above:\n\nPresent Value: $25,000 received in 3 years at 4.5% interest is worth $_____ today\nLiquidity Ratios:\n\nCurrent Ratio: _____ (does/doesn’t meet the 2.0 benchmark)\nQuick Ratio: _____ (indicates the company can/cannot pay short-term debts without selling inventory)\n\nProfitability: The company achieved an average profit margin of _____% in Q1\nAsset Management: The equipment will have a book value of $_____ after 5 years"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Accounting Analytics Site",
    "section": "",
    "text": "Welcome! I’m a student in Sonoma State University’s accounting program, exploring data analytics in accounting. This website showcases my work:\n\nData analysis projects using R and accounting datasets\nCourse reflections on key concepts and applications\nProfessional development in accounting technology"
  },
  {
    "objectID": "index.html#about-this-site",
    "href": "index.html#about-this-site",
    "title": "Welcome to My Accounting Analytics Site",
    "section": "",
    "text": "Welcome! I’m a student in Sonoma State University’s accounting program, exploring data analytics in accounting. This website showcases my work:\n\nData analysis projects using R and accounting datasets\nCourse reflections on key concepts and applications\nProfessional development in accounting technology"
  },
  {
    "objectID": "index.html#skills-im-developing",
    "href": "index.html#skills-im-developing",
    "title": "Welcome to My Accounting Analytics Site",
    "section": "Skills I’m Developing",
    "text": "Skills I’m Developing\n\nFinancial data analysis with R\nData visualization for accounting insights\nStatistical modeling for audit analytics\nDatabase management for accounting systems"
  },
  {
    "objectID": "index.html#posts",
    "href": "index.html#posts",
    "title": "Welcome to My Accounting Analytics Site",
    "section": "Posts",
    "text": "Posts"
  },
  {
    "objectID": "posts/05-data-governance.html",
    "href": "posts/05-data-governance.html",
    "title": "5: Data Governance and Management",
    "section": "",
    "text": "Write a 2-3 sentence summary of your data governance implementations and key insights here after completing the assignment."
  },
  {
    "objectID": "posts/05-data-governance.html#executive-summary",
    "href": "posts/05-data-governance.html#executive-summary",
    "title": "5: Data Governance and Management",
    "section": "",
    "text": "Write a 2-3 sentence summary of your data governance implementations and key insights here after completing the assignment."
  },
  {
    "objectID": "posts/05-data-governance.html#introduction",
    "href": "posts/05-data-governance.html#introduction",
    "title": "5: Data Governance and Management",
    "section": "Introduction",
    "text": "Introduction\nAs an accounting professional, you need to ensure data integrity, quality, and compliance. Effective data governance helps organizations:\n\nMaintain accurate and consistent financial records\nEnsure referential integrity between related data\nDocument data structures for audit and compliance\nImplement controls to prevent errors and fraud\n\nIn this blog post, you will:\n\nCreate validation functions for accounting data standards\nBuild referential integrity checks between tables\nDesign a comprehensive data dictionary"
  },
  {
    "objectID": "posts/05-data-governance.html#setup-and-load-libraries",
    "href": "posts/05-data-governance.html#setup-and-load-libraries",
    "title": "5: Data Governance and Management",
    "section": "Setup and Load Libraries",
    "text": "Setup and Load Libraries\n\nRequired Libraries\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation\nlibrary(gt)         # For formatted tables\nlibrary(lubridate)  # For date handling\n\n\n\nSetting Up Sample Data\nLet’s create sample data representing accounting records:\nChart of Accounts Master Data\n\n# Create chart of accounts\nchart_of_accounts &lt;- tribble(\n  ~account_id, ~account_code, ~account_name,        ~account_type, ~active,\n  1,           \"1010\",        \"Cash\",               \"Asset\",       TRUE,\n  2,           \"1200\",        \"Accounts Receivable\",\"Asset\",       TRUE,\n  3,           \"2010\",        \"Accounts Payable\",   \"Liability\",   TRUE,\n  4,           \"3010\",        \"Common Stock\",       \"Equity\",      TRUE,\n  5,           \"4010\",        \"Sales Revenue\",      \"Revenue\",     TRUE,\n  6,           \"5010\",        \"Rent Expense\",       \"Expense\",     TRUE,\n  7,           \"5020\",        \"Salary Expense\",     \"Expense\",     FALSE\n)\n\n# View the data\nchart_of_accounts\n\nSample Transactions\n\n# Create sample transactions (some with errors)\ntransactions &lt;- tribble(\n  ~trans_id, ~trans_date,    ~account_id, ~debit,  ~credit, ~description,\n  \"T001\",    \"2025-03-15\",   1,           5000,    0,       \"Customer payment\",\n  \"T002\",    \"2025-03-15\",   5,           0,       5000,    \"Sales revenue\",\n  \"T003\",    \"03/20/2025\",   6,           1200,    0,       \"Rent payment\",\n  \"T004\",    \"2025-03-32\",   3,           0,       1200,    \"Rent payable\",\n  \"T005\",    \"2025-03-25\",   99,          500,     0,       \"Office supplies\",\n  \"T006\",    \"2025-03-25\",   2,           0,       500,     \"Customer invoice\"\n)\n\n# View the data\ntransactions"
  },
  {
    "objectID": "posts/05-data-governance.html#exercise-1-data-standards-implementation",
    "href": "posts/05-data-governance.html#exercise-1-data-standards-implementation",
    "title": "5: Data Governance and Management",
    "section": "Exercise 1: Data Standards Implementation",
    "text": "Exercise 1: Data Standards Implementation\n\nCreate Account Code Validation Function\n\n# Function to validate account codes\nvalidate_account_code &lt;- function(account_code) {\n  # Check if account code is exactly 4 digits\n  is_valid &lt;- str_detect(account_code, \"^\\\\d{_____}$\")\n  \n  return(is_valid)\n}\n\n# Test the function\ntest_codes &lt;- c(\"1010\", \"ABC1\", \"10100\", \"999\")\n\n# Create results table\nvalidation_results &lt;- tibble(\n  account_code = test_codes,\n  is_valid = map_lgl(_____, validate_account_code)\n)\n\n# Display results\nvalidation_results\n\n\n\nCreate Date Validation Function\n\n# Function to validate transaction dates\nvalidate_date &lt;- function(date_string) {\n  # Try to parse the date\n  parsed_date &lt;- suppressWarnings(as_date(date_string))\n  \n  # Check if parsing was successful\n  if (is.na(parsed_date)) {\n    return(list(valid = FALSE, reason = \"Invalid date format\"))\n  }\n  \n  # Check if date is not in the future\n  if (parsed_date &gt; _____) {  # Compare to today's date\n    return(list(valid = _____, reason = \"Date cannot be in the future\"))\n  }\n  \n  # Check if date is reasonable (not before 2020)\n  if (parsed_date &lt; as_date(\"_____\")) {\n    return(list(valid = FALSE, reason = \"Date too far in the past\"))\n  }\n  \n  return(list(valid = TRUE, reason = \"Valid date\"))\n}\n# Test dates\ntest_dates &lt;- c(\"2025-03-15\", \"03/20/2025\", \"2025-03-32\", \"2028-01-01\", \"2019-01-01\")\n\n# Validate each date\ndate_validation &lt;- tibble(\n  date_string = test_dates,\n  validation = map(_____, validate_date)\n) |&gt;\n  mutate(\n    is_valid = map_lgl(validation, ~ .$valid),\n    reason = map_chr(validation, ~ ._____) \n  ) |&gt;\n  select(-validation)\n\n# Display results\ndate_validation"
  },
  {
    "objectID": "posts/05-data-governance.html#exercise-2-referential-integrity-check",
    "href": "posts/05-data-governance.html#exercise-2-referential-integrity-check",
    "title": "5: Data Governance and Management",
    "section": "Exercise 2: Referential Integrity Check",
    "text": "Exercise 2: Referential Integrity Check\n\nCreate Referential Integrity Function\n\n# Function to check if all account IDs exist in chart of accounts\ncheck_referential_integrity &lt;- function(transactions_df, chart_of_accounts_df) {\n  # Get valid account IDs from chart of accounts\n  valid_account_ids &lt;- chart_of_accounts_df$_____\n  \n  # Find transactions with invalid account IDs\n  invalid_transactions &lt;- transactions_df |&gt;\n    filter(!_____ %in% valid_account_ids)\n  \n  # Check if debits equal credits by date\n  daily_balance &lt;- transactions_df |&gt;\n    group_by(_____) |&gt;\n    summarize(\n      total_debits = sum(debit),\n      total_credits = sum(_____),\n      difference = round(total_debits - _____ , 2)\n    ) |&gt;\n    filer(difference != 0)\n  \n  # Return results\n  return(list(\n    has_invalid_accounts = nrow(invalid_transactions) &gt; 0,\n    invalid_transactions = invalid_transactions,\n    has_unbalanced_days = nrow(daily_balance) &gt; 0,\n    unbalanced_days = daily_balance\n  ))\n}\n\n# Check referential integrity\nintegrity_check &lt;- check_referential_integrity(_____, _____)\n\n# Display invalid account references\nif (integrity_check$has_invalid_accounts) {\n  cat(\"Invalid Account References Found:\\n\")\n  print(integrity_check$invalid_transactions)\n}\n\n# Display unbalanced days\nif (integrity_check$_____) {\n  cat(\"\\nUnbalanced Transaction Days:\\n\")\n  print(integrity_check$_____)\n}"
  },
  {
    "objectID": "posts/05-data-governance.html#exercise-3-data-dictionary-creation",
    "href": "posts/05-data-governance.html#exercise-3-data-dictionary-creation",
    "title": "5: Data Governance and Management",
    "section": "Exercise 3: Data Dictionary Creation",
    "text": "Exercise 3: Data Dictionary Creation\n\nDesign AR System Data Dictionary\nCreate a comprehensive data dictionary for an accounts receivable system with the following structure:\n\n# Create AR data dictionary\nar_data_dictionary &lt;- tribble(\n  ~field_name,        ~data_type,     ~max_length, ~required, ~description,                          ~valid_values,                    ~business_rules,\n  \"customer_id\",      \"VARCHAR\",      10,          \"Yes\",     \"Unique customer identifier\",          \"C0001-C9999\",                   \"System generated, sequential\",\n  \"customer_name\",    \"VARCHAR\",      100,         \"Yes\",     \"_____\",                              \"Any valid business name\",        \"Must match legal entity name\",\n  \"invoice_number\",   \"_____\",        20,          \"Yes\",     \"Unique invoice identifier\",           \"INV-YYYY-NNNNN\",                \"Year + sequential number\",\n  \"invoice_date\",     \"DATE\",         NA,          \"Yes\",     \"Date invoice was issued\",             \"Valid date\",                    \"_____\",\n  \"due_date\",         \"DATE\",         NA,          \"Yes\",     \"_____\",                              \"Valid date\",                    \"Must be &gt;= invoice_date\",\n  \"invoice_amount\",   \"DECIMAL(10,2)\", NA,         \"Yes\",     \"Total invoice amount\",                \"&gt; 0\",                          \"Must be positive\",\n  \"payment_status\",   \"VARCHAR\",      20,          \"_____\",   \"Current payment status\",              \"Open, Partial, Paid, Overdue\",  \"Updated based on payments\",\n  \"days_outstanding\", \"INTEGER\",      NA,          \"No\",      \"_____\",                              \"&gt;= 0\",                          \"Calculated: Today - Invoice Date\"\n)\n\n# Display the data dictionary\nar_data_dictionary |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Accounts Receivable System Data Dictionary\",\n    subtitle = \"Field Specifications and Business Rules\"\n  ) |&gt;\n  tab_style(\n    style = cell_fill(color = \"lightblue\"),\n    locations = cells_body(\n      columns = required,\n      rows = required == \"Yes\"\n    )\n  )"
  },
  {
    "objectID": "posts/05-data-governance.html#summary-and-best-practices",
    "href": "posts/05-data-governance.html#summary-and-best-practices",
    "title": "5: Data Governance and Management",
    "section": "Summary and Best Practices",
    "text": "Summary and Best Practices\n\nKey Validation Rules Implemented\n\n# Summarize validation rules\nvalidation_summary &lt;- tribble(\n  ~validation_type,        ~rule_description,                               ~purpose,\n  \"Account Code Format\",   \"_____\",                                         \"Ensures consistent account identification\",\n  \"Date Validation\",       \"Valid format, not future, reasonable range\",    \"_____\",\n  \"Referential Integrity\", \"_____\",                                         \"Prevents orphaned transactions\",\n  \"Balance Check\",         \"Daily debits must equal credits\",               \"_____\",\n  \"Required Fields\",       \"Check for NULL in required fields\",             \"Data completeness\"\n)\n\n# Display summary\nvalidation_summary |&gt;\n  gt() |&gt;\n  tab_header(title = \"Data Governance Validation Rules\")"
  },
  {
    "objectID": "posts/05-data-governance.html#key-findings",
    "href": "posts/05-data-governance.html#key-findings",
    "title": "5: Data Governance and Management",
    "section": "Key Findings",
    "text": "Key Findings\nBased on your data governance implementation, complete these insights:\n\nData Quality Issues Found: The sample transactions had _____ invalid account reference.\nDate Validation: There were _____ valid dates and _____ non-valid dates (out of 5).\nReferential Integrity: _____ transactions referenced non-existent accounts and _____ transactions had unbalanced transaction days.\nData Dictionary Completeness: The AR system requires _____ mandatory fields out of _____ total fields."
  },
  {
    "objectID": "posts/03-data-wrangling.html",
    "href": "posts/03-data-wrangling.html",
    "title": "3: Data Wrangling",
    "section": "",
    "text": "Write a 2-3 sentence summary of your analysis and key findings here after completing the assignment."
  },
  {
    "objectID": "posts/03-data-wrangling.html#executive-summary",
    "href": "posts/03-data-wrangling.html#executive-summary",
    "title": "3: Data Wrangling",
    "section": "",
    "text": "Write a 2-3 sentence summary of your analysis and key findings here after completing the assignment."
  },
  {
    "objectID": "posts/03-data-wrangling.html#introduction",
    "href": "posts/03-data-wrangling.html#introduction",
    "title": "3: Data Wrangling",
    "section": "Introduction",
    "text": "Introduction\nAs an accounting professional, you’ll often receive data that needs cleaning before analysis. Common issues include:\n\nInconsistent date formats (01/15/2027 vs 2027-01-15)\nMixed number formats ($1,234.56 vs 1234.56)\nInconsistent text (ACME CORP vs Acme Corp vs acme corp)\nData stored in multiple systems that need to be combined\n\nIn this blog post, you will:\n\nIdentify data quality issues\nClean messy accounting data\nCombine data from multiple sources\nCreate professional summaries"
  },
  {
    "objectID": "posts/03-data-wrangling.html#setup-and-load-libraries",
    "href": "posts/03-data-wrangling.html#setup-and-load-libraries",
    "title": "3: Data Wrangling",
    "section": "Setup and Load Libraries",
    "text": "Setup and Load Libraries\n\nRequired Libraries\n\n# Load required packages\nlibrary(tidyverse)  # For data manipulation\nlibrary(scales)     # For formatting numbers\n\n\n\nCreating Sample Data\nLet’s create sample data that shows common accounting data problems:\nSales Transaction Data\n\n# Sales data with typical formatting issues\nsales_raw &lt;- tribble(\n  ~transaction_id, ~customer_id, ~sale_date,     ~amount,       ~product_category,\n  \"TXN-001\",      \"CUST001\",    \"01/15/2027\",   \"$25,000.00\",  \"Software\",\n  \"TXN-002\",      \"CUST002\",    \"01/20/2027\",   \"15000\",       \"Hardware\", \n  \"TXN-003\",      \"CUST003\",    \"2027-02-01\",   \"$8,750.50\",   \"Services\",\n  \"TXN-004\",      \"CUST001\",    \"02/15/2027\",   \"12000.00\",    \"software\",\n  \"TXN-005\",      \"CUST999\",    \"02/28/2027\",   \"$5,500\",      \"Hardware\", # Bad customer\n  \"TXN-006\",      \"CUST004\",    \"3/10/2027\",    \"18500\",       \"Services\",\n  \"TXN-007\",      \"CUST002\",    \"03/15/2027\",   \"$22,000\",     \"Software\",\n  \"TXN-008\",      \"CUST003\",    \"2027-03-20\",   \"9750.00\",     \"HARDWARE\"\n)\n\n# View the raw data\nsales_raw\n\nCustomer Master Data\n\n# Customer data with inconsistent formatting\ncustomers_raw &lt;- tribble(\n  ~customer_id, ~customer_name,      ~region, ~segment,\n  \"CUST001\",   \"acme corporation\",   \"North\", \"Enterprise\",\n  \"CUST002\",   \"GLOBEX INC\",        \"South\", \"Mid-Market\",\n  \"CUST003\",   \"umbrella corp\",      \"West\",  \"\",           # Missing segment\n  \"CUST004\",   \"Stark Industries\",   \"East\",  \"Enterprise\",\n  \"CUST005\",   \"wayne enterprises\",  \"North\", \"Enterprise\"  # No sales in Q1\n)\n\n# View the raw customer data\ncustomers_raw\n\n\n\nIdentifying Data Quality Issues\nBefore cleaning, let’s identify the problems:\nCheck Date Formats\n\n# Look at the different date formats\nsales_raw |&gt; \n  select(sale_date) |&gt;\n  distinct()\n\nCheck Amount Formats\n\n# Look at the different amount formats\nsales_raw |&gt;\n  select(amount) |&gt;\n  distinct()\n\nCheck Customer Name Consistency\n\n# Look at customer name formatting\ncustomers_raw |&gt;\n  select(customer_name)\n\nFind Missing Data\n\n# Check for blank segments\ncustomers_raw |&gt;\n  filter(segment == \"\")\n\n\n\nCleaning the Data\n\nStep 1: Clean Sales Data\n\n# Clean the sales data\nsales_clean &lt;- sales_raw |&gt;\n  mutate(\n    # Fix dates: parse_date_time can handle multiple formats\n    sale_date = parse_date_time(_____, orders = c(\"mdy\", \"ymd\")) |&gt; \n                as_date(),\n    \n    # Fix amounts: remove $ and , then convert to number\n    amount = str_remove_all(amount, \"[___]\") |&gt;  # Remove $ and ,\n             as.numeric(),\n    \n    # Standardize text to Title Case\n    product_category = str_to_title(_____),\n    \n    # Add useful columns for reporting\n    month_name = month(sale_date, label = TRUE, abbr = FALSE)\n  )\n# View cleaned sales data\nsales_clean\n\n\n\nStep 2: Clean Customer Data\n\n# Clean the customer data\ncustomers_clean &lt;- customers_raw |&gt;\n  mutate(\n    # Standardize customer names to Title Case\n    customer_name = str_to_title(_____),\n    \n    # Replace blank segments with \"Unclassified\"\n    segment = if_else(segment == \"\", \"_____\", segment)\n  )\n\n# View cleaned customer data\ncustomers_clean\n\n\n\n\nCombining the Data\n\nJoin Sales with Customer Information\n\n# Combine sales and customer data\n# Use left_join to keep all sales, even if customer not found\nsales_complete &lt;- sales_clean |&gt;\n  left_join(_____, by = \"_____\")\n\n# View the combined data\nglimpse(sales_complete)\n\n\n\nCheck for Data Quality Issues\n\n# Find sales without valid customer info\nproblem_sales &lt;- sales_complete |&gt;\n  filter(is.na(_____)) |&gt;  # Check for missing customer_name\n  select(transaction_id, customer_id, amount, sale_date)\n\nproblem_sales\n\n\n\n\nAnalysis and Insights\n\nMonthly Sales Summary\n\n# Calculate monthly sales (excluding problem transactions)\nmonthly_sales &lt;- sales_complete |&gt;\n  filter(!is.na(customer_name)) |&gt;  # Only valid customers\n  group_by(_____) |&gt;  # Group by month_name\n  summarise(\n    total_sales = sum(_____),\n    transaction_count = n(),\n    average_sale = mean(_____)\n  )\n\n# View monthly summary\nmonthly_sales\n\n# Format as currency\nmonthly_sales |&gt;\n  mutate(\n    total_sales = dollar(total_sales),\n    average_sale = dollar(average_sale)\n  )\n\n\n\nSales by Product Category\n\n# Analyze sales by product\nproduct_summary &lt;- sales_complete |&gt;\n  filter(!is.na(customer_name)) |&gt;\n  group_by(_____) |&gt;  # Group by product_category\n  summarise(\n    total_sales = sum(amount),\n    count = n()\n  ) |&gt;\n  mutate(\n    percentage = (total_sales / sum(total_sales)) * 100\n  ) |&gt;\n  arrange(desc(total_sales))\n\n# View product summary\nproduct_summary\n\n\n\nCustomer Segment Analysis\n\n# Analyze by customer segment\nsegment_summary &lt;- sales_complete |&gt;\n  filter(!is.na(customer_name)) |&gt;\n  group_by(_____) |&gt;  # Group by segment\n  summarise(\n    total_sales = sum(amount),\n    customer_count = n_distinct(_____),  # Count unique customers\n    avg_per_customer = total_sales / customer_count\n  )\n\n# View segment summary with formatting\nsegment_summary |&gt;\n  mutate(\n    total_sales = dollar(total_sales),\n    avg_per_customer = dollar(avg_per_customer)\n  )"
  },
  {
    "objectID": "posts/03-data-wrangling.html#key-findings",
    "href": "posts/03-data-wrangling.html#key-findings",
    "title": "3: Data Wrangling",
    "section": "Key Findings",
    "text": "Key Findings\nData Quality Report\n\n# Calculate data quality metrics\ntotal_transactions &lt;- nrow(sales_complete)\nvalid_transactions &lt;- sum(!is.na(sales_complete$customer_name))\nproblem_transactions &lt;- sum(is.na(sales_complete$customer_name))\n\n# Create summary\ndata_quality &lt;- tibble(\n  Metric = c(\"Total Transactions\", \n            \"Valid Transactions\", \n            \"Problem Transactions\",\n            \"Data Quality Rate\"),\n  Value = c(total_transactions,\n            valid_transactions,\n            problem_transactions,\n            percent(valid_transactions/total_transactions) )\n)\n\ndata_quality\n\n\nBusiness Insights\nBased on the analysis above, complete these insights:\n\nMonthly Trend: Sales (increased/decreased) from January to March, with the highest sales in _____.\nProduct Performance: _____ generated the most revenue, accounting for _____% of total sales.\nCustomer Segments: The _____ segment had the highest average sale per customer at $_____.\nData Quality: We identified _____ transaction(s) with invalid customer IDs that need investigation."
  },
  {
    "objectID": "posts/04_data_visualization.html",
    "href": "posts/04_data_visualization.html",
    "title": "4: Data Visualization for Accounting",
    "section": "",
    "text": "Write a 2-3 sentence summary of your visualizations and key insights here after completing the assignment."
  },
  {
    "objectID": "posts/04_data_visualization.html#executive-summary",
    "href": "posts/04_data_visualization.html#executive-summary",
    "title": "4: Data Visualization for Accounting",
    "section": "",
    "text": "Write a 2-3 sentence summary of your visualizations and key insights here after completing the assignment."
  },
  {
    "objectID": "posts/04_data_visualization.html#introduction",
    "href": "posts/04_data_visualization.html#introduction",
    "title": "4: Data Visualization for Accounting",
    "section": "Introduction",
    "text": "Introduction\nAs an accounting professional, you need to communicate complex financial information clearly. Effective data visualization helps stakeholders understand:\n\nFinancial performance trends\nBudget variances and anomalies\nDepartmental spending patterns\nRevenue growth across customer segments\n\nIn this blog post, you will:\n\nCreate professional bar charts for categorical comparisons\nBuild line charts to show financial trends\nDesign dashboard layouts for comprehensive reporting\nApply best practices for ethical data visualization"
  },
  {
    "objectID": "posts/04_data_visualization.html#setup-and-load-libraries",
    "href": "posts/04_data_visualization.html#setup-and-load-libraries",
    "title": "4: Data Visualization for Accounting",
    "section": "Setup and Load Libraries",
    "text": "Setup and Load Libraries\n\nRequired Libraries\n\n# Load required packages\nlibrary(tidyverse)  # For ggplot2 and data manipulation\nlibrary(scales)     # For formatting currency and percentages\nlibrary(patchwork)  # For combining multiple plots\n\n\n\nCreating Sample Financial Data\nLet’s create sample data representing a company’s financial performance:\nMonthly Financial Performance\n\n# Monthly financial data for 2027\nmonthly_financials &lt;- tribble(\n  ~month, ~revenue, ~expenses, ~net_income, ~quarter,\n  \"2027-01-01\", 125000, 95000, 30000, \"Q1\",\n  \"2027-02-01\", 135000, 98000, 37000, \"Q1\",\n  \"2027-03-01\", 142000, 102000, 40000, \"Q1\",\n  \"2027-04-01\", 155000, 110000, 45000, \"Q2\",\n  \"2027-05-01\", 148000, 108000, 40000, \"Q2\",\n  \"2027-06-01\", 162000, 115000, 47000, \"Q2\",\n  \"2027-07-01\", 158000, 112000, 46000, \"Q3\",\n  \"2027-08-01\", 171000, 120000, 51000, \"Q3\",\n  \"2027-09-01\", 166000, 118000, 48000, \"Q3\",\n  \"2027-10-01\", 180000, 125000, 55000, \"Q4\",\n  \"2027-11-01\", 195000, 135000, 60000, \"Q4\",\n  \"2027-12-01\", 210000, 145000, 65000, \"Q4\"\n) |&gt;\n  mutate(month = as.Date(month))\n\n# View the data\nmonthly_financials\n\nDepartment Expense Data\n\n# Department expense breakdown\ndept_expenses &lt;- tribble(\n  ~department, ~expense_category, ~amount,\n  \"Sales\", \"Salaries\", 225236,\n  \"Sales\", \"Travel\", 75308,\n  \"Sales\", \"Supplies\", 34419,\n  \"Marketing\", \"Salaries\", 179800,\n  \"Marketing\", \"Advertising\", 134369,\n  \"Marketing\", \"Supplies\", 29876,\n  \"Operations\", \"Salaries\", 270664,\n  \"Operations\", \"Equipment\", 88937,\n  \"Operations\", \"Supplies\", 57135,\n  \"Finance\", \"Salaries\", 202516,\n  \"Finance\", \"Software\", 57135,\n  \"Finance\", \"Supplies\", 27605\n)\n\n# View the data\ndept_expenses\n\n\n\nSetting Professional Defaults\n\n# Set a clean theme for all plots\ntheme_set(theme_minimal())\n\n# Prevent scientific notation in output\noptions(scipen = 9999)"
  },
  {
    "objectID": "posts/04_data_visualization.html#creating-your-first-visualization",
    "href": "posts/04_data_visualization.html#creating-your-first-visualization",
    "title": "4: Data Visualization for Accounting",
    "section": "Creating Your First Visualization",
    "text": "Creating Your First Visualization\n\nBar Chart: Department Total Expenses\n\n# Calculate total expenses by department\ndept_totals &lt;- dept_expenses |&gt;\n  group_by(_____) |&gt;  # Group by department\n  summarize(total_expenses = _____) |&gt;  # Sum the amounts\n  arrange(desc(total_expenses))\n\n# Display dept_totals\ndept_totals\n\n# Create a horizontal bar chart\nggplot(dept_totals, aes(x = _____, y = reorder(department, _____))) +\n  geom_col(fill = \"dark blue\") +\n  scale_x_continuous(labels = _____) +  # Format as currency\n  labs(\n    title = \"Total Expenses by Department\",\n    subtitle = \"Fiscal Year 2027\",\n    x = NULL,\n    y = NULL,\n    caption = \"Source: General Ledger\"\n  )\n\n\n\nLine Chart: Revenue Trend Analysis\n\n# Create a line chart showing monthly revenue\nmonthly_financials |&gt;\n  ggplot(aes(x = _____, y = _____)) +  # Map month to x, revenue to y\n  geom_line(color = \"dark green\", size = 1.2) +\n  geom_point(color = \"dark green\", size = 2.5) +\n  scale_x_date(\n    labels = label_date_short(), \n    breaks = breaks_width(\"1 months\")) +\n  scale_y_continuous(labels = _____) +  # Format as currency\n  labs(\n    title = \"_____\",  # Add appropriate title\n    subtitle = \"January - December 2027\",\n    x = NULL,\n    y = NULL,\n    caption = \"Source: Financial Reporting System\"\n  )"
  },
  {
    "objectID": "posts/04_data_visualization.html#multi-series-line-chart",
    "href": "posts/04_data_visualization.html#multi-series-line-chart",
    "title": "4: Data Visualization for Accounting",
    "section": "Multi-Series Line Chart",
    "text": "Multi-Series Line Chart\n\nComparing Revenue vs Expenses\n\n# Transform data for multi-line plotting\nfinancial_trends &lt;- monthly_financials |&gt;\n  select(month, revenue, expenses) |&gt;\n  pivot_longer(\n    cols = c(_____, _____),  # Select revenue and expenses columns\n    names_to = \"metric\",\n    values_to = \"amount\"\n  )\n\n\n# Display financial_trends\n_____\n\n\n# Create multi-line chart\nggplot(financial_trends, aes(x = month, y = amount, color = _____)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  scale_x_date(\n    labels = label_date_short(),\n    breaks = breaks_width(\"3 months\")) +\n  scale_y_continuous(labels = dollar_format()) +\n  scale_color_manual(\n    values = c(\"revenue\" = \"_____\", \"expenses\" = \"_____\"),  # Choose appropriate colors\n    labels = c(\"revenue\" = \"Revenue\", \"expenses\" = \"Expenses\"),\n    breaks = c(\"revenue\", \"expenses\") # Set order of legend items\n  ) +\n  labs(\n    title = \"Revenue vs Expenses Trend\",\n    subtitle = \"2027 Financial Performance\",\n    x = NULL,\n    y = NULL,\n    color = NULL\n  ) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "posts/04_data_visualization.html#department-expense-breakdown",
    "href": "posts/04_data_visualization.html#department-expense-breakdown",
    "title": "4: Data Visualization for Accounting",
    "section": "Department Expense Breakdown",
    "text": "Department Expense Breakdown\n\nStacked Bar Chart by Category\n\n# Create stacked bar chart showing expense categories\ndept_expenses |&gt;\n  ggplot(aes(x = department, y = amount, fill = _____)) +  # Fill by expense_category\n  geom_col(position = \"_____\") +  # Use \"stack\" position\n  scale_y_continuous(labels = dollar_format()) +\n  scale_fill_brewer(palette = \"Blues\") +\n  labs(\n    title = \"Department Expenses by Category\",\n    subtitle = \"Fiscal Year 2027\",\n    x = NULL,\n    y = NULL,\n    fill = NULL,\n    caption = \"Source: General Ledger\"\n  ) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "posts/04_data_visualization.html#creating-a-financial-dashboard",
    "href": "posts/04_data_visualization.html#creating-a-financial-dashboard",
    "title": "4: Data Visualization for Accounting",
    "section": "Creating a Financial Dashboard",
    "text": "Creating a Financial Dashboard\n\nPanel 1: Net Income Trend\n\n# Create net income visualization\np1 &lt;- monthly_financials |&gt;\n  ggplot(aes(x = month, y = _____)) +  # Plot net_income\n  geom_col(fill = ifelse(monthly_financials$net_income &gt; 0, \"seagreen\", \"tomato\")) +\n  scale_x_date(labels = label_date_short()) +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Monthly Net Income\",\n    x = NULL,\n    y = NULL\n  )\n\n# Display p1\n_____\n\n\n\nPanel 2: Quarterly Performance\n\n# Summarize by quarter\nquarterly_summary &lt;- monthly_financials |&gt;\n  group_by(_____) |&gt;  # Group by quarter\n  summarize(\n    total_revenue = sum(_____),\n    total_expenses = sum(_____),\n    total_net_income = sum(_____)\n  )\n\n# Display quarterly_summary\n_____\n\n# Create quarterly comparison\np2 &lt;- quarterly_summary |&gt;\n  ggplot(aes(x = _____)) +\n  geom_col(aes(y = total_revenue), fill = \"seagreen\") +\n  geom_col(aes(y = -total_expenses), fill = \"tomato\") +\n  scale_y_continuous(\n    labels = function(x) dollar_format()(abs(x))\n  ) +\n  labs(\n    title = \"Quarterly Revenue vs Expenses\",\n    subtitle = \"Revenue (green) above, Expenses (red) below\",\n    x = NULL,\n    y = NULL\n  )\n\n\n# Display p2\np2\n\n\n\nCombine Dashboard Panels\n\n# Combine panels using patchwork\ndashboard &lt;- p1 / p2\n\n# Display dashboard\ndashboard +\n  plot_annotation(\n    title = \"Financial Performance Dashboard\",\n    subtitle = \"Fiscal Year 2027\",\n    caption = \"Source: Financial Reporting System\"\n  )"
  },
  {
    "objectID": "posts/04_data_visualization.html#advanced-visualization-variance-analysis",
    "href": "posts/04_data_visualization.html#advanced-visualization-variance-analysis",
    "title": "4: Data Visualization for Accounting",
    "section": "Advanced Visualization: Variance Analysis",
    "text": "Advanced Visualization: Variance Analysis\n\n# Create budget vs actual data\nbudget_data &lt;- tribble(\n  ~department, ~budget, ~actual,\n  \"Sales\", 350000, 334963,\n  \"Marketing\", 320000, 344045,\n  \"Operations\", 420000, 416736,\n  \"Finance\", 280000, 287256\n) |&gt;\n  mutate(\n    variance_amount = _____ - _____,  # Calculate variance\n    variance_pct = (variance_amount / budget) * 100,\n    favorable = variance_amount &lt; 0  # For expenses, under budget is favorable\n  )\n\n\n# Display budget_data\n_____\n\n\n# Create variance visualization\nbudget_data |&gt;\n  ggplot(aes(x = variance_pct, y = reorder(department, variance_pct))) +\n  geom_col(aes(fill = favorable)) +\n  scale_fill_manual(\n    values = c(\"TRUE\" = \"_____\", \"FALSE\" = \"_____\"),  # Green for favorable, red for unfavorable\n    labels = c(\"TRUE\" = \"Favorable\", \"FALSE\" = \"Unfavorable\")\n  ) +\n  scale_x_continuous(labels = percent_format(scale = 1)) +\n  labs(\n    title = \"Budget Variance by Department\",\n    subtitle = \"Percentage Over/Under Budget\",\n    x = NULL,\n    y = NULL,\n    fill = NULL\n  ) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "posts/04_data_visualization.html#key-insights-and-best-practices",
    "href": "posts/04_data_visualization.html#key-insights-and-best-practices",
    "title": "4: Data Visualization for Accounting",
    "section": "Key Insights and Best Practices",
    "text": "Key Insights and Best Practices\n\nData Visualization Ethics\n\n# Example of ethical vs misleading visualization\n# Create the same data with different y-axis scales\n\n# Misleading (truncated y-axis)\nmisleading &lt;- monthly_financials |&gt;\n  ggplot(aes(x = month, y = revenue)) +\n  geom_line(color = \"dark green\", size = 1.2) +\n  scale_y_continuous(\n    limits = c(120000, 220000),  # Truncated axis\n    labels = dollar_format()\n  ) +\n  labs(title = \"MASSIVE Revenue Growth!\")\n\n# Ethical (starts at zero)\nethical &lt;- monthly_financials |&gt;\n  ggplot(aes(x = month, y = revenue)) +\n  geom_line(color = \"dark green\", size = 1.2) +\n  scale_y_continuous(\n    limits = c(0, NA),  # Start at zero\n    labels = dollar_format()\n  ) +\n  labs(title = \"Monthly Revenue Growth\")\n\n# Compare side by side\nmisleading | ethical\n\n\n\nSummary Metrics\n\n# Calculate key performance metrics\nperformance_summary &lt;- monthly_financials |&gt;\n  summarize(\n    total_revenue = sum(revenue),\n    total_expenses = sum(expenses),\n    total_net_income = sum(net_income),\n    profit_margin = (total_net_income / total_revenue),\n    revenue_growth = ((last(revenue) - first(revenue)) / first(revenue)) \n  )\n\n\n# Display performance_summary\nperformance_summary\n\n\n# Format the summary\nperformance_summary |&gt;\n  mutate(\n    total_revenue = dollar(total_revenue),\n    total_expenses = dollar(total_expenses),\n    total_net_income = dollar(total_net_income),\n    profit_margin = percent(profit_margin),\n    revenue_growth = percent(revenue_growth)\n  )"
  },
  {
    "objectID": "posts/04_data_visualization.html#key-findings",
    "href": "posts/04_data_visualization.html#key-findings",
    "title": "4: Data Visualization for Accounting",
    "section": "Key Findings",
    "text": "Key Findings\nBased on the visualizations above, complete these insights:\n\nRevenue Trend: Revenue (increased/decreased) by _____% from January to December.\nHighest Spending Department: _____ had the highest total expenses at $_____.\nProfit Margin: The company achieved a _____% profit margin for the year.\nBest Performing Quarter: Q_____ showed the highest net income at $_____.\nBudget Performance: The _____ and _____ departments were under budget (favorable variance)."
  },
  {
    "objectID": "posts/08-sol-classification.html",
    "href": "posts/08-sol-classification.html",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "",
    "text": "Our classification analysis developed a decision tree model that achieved 92% accuracy in detecting fraudulent transactions. The model identified transaction amount, vendor type, and documentation score as the strongest fraud predictors, enabling focused investigation of just 12% of transactions while catching 73% of fraud cases."
  },
  {
    "objectID": "posts/08-sol-classification.html#executive-summary",
    "href": "posts/08-sol-classification.html#executive-summary",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "",
    "text": "Our classification analysis developed a decision tree model that achieved 92% accuracy in detecting fraudulent transactions. The model identified transaction amount, vendor type, and documentation score as the strongest fraud predictors, enabling focused investigation of just 12% of transactions while catching 73% of fraud cases."
  },
  {
    "objectID": "posts/08-sol-classification.html#introduction",
    "href": "posts/08-sol-classification.html#introduction",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Introduction",
    "text": "Introduction\nAs an accounting professional implementing fraud detection systems, you need to build models that can automatically identify potentially fraudulent transactions. Classification analysis helps auditors:\n\nPredict whether transactions are fraudulent or legitimate\nPrioritize high-risk transactions for investigation\nReduce manual review workload\nImprove fraud detection consistency\n\nIn this blog post, you will:\n\nBuild a decision tree model for fraud detection\nEvaluate model performance with business metrics\nAnalyze which factors best predict fraud\nRecommend implementation strategies for the fraud detection system"
  },
  {
    "objectID": "posts/08-sol-classification.html#setup-and-load-libraries",
    "href": "posts/08-sol-classification.html#setup-and-load-libraries",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Setup and Load Libraries",
    "text": "Setup and Load Libraries\n\nRequired Libraries\n\n# Load packages we need - matching the slides\nlibrary(tidyverse)    # For data manipulation\nlibrary(tidymodels)   # For classification modeling\nlibrary(scales)       # For formatting numbers\nlibrary(gt)           # For nice tables\nlibrary(rpart.plot)   # For visualizing decision trees\nlibrary(vip)          # For variable importance\n\n# Set preferences\ntheme_set(theme_minimal())  # Clean plots\noptions(scipen = 999)       # No scientific notation\nset.seed(2027)              # Reproducible results\n\n\n\nLoad and Explore the Data\n\n# Load the fraud detection data\n# Note: Using simulated data for this solution\nset.seed(2027)\nfraud_data &lt;- tibble(\n  transaction_id = 1:330,\n  amount = c(rnorm(300, 3000, 1500), rnorm(30, 8000, 3000)),\n  vendor_type = sample(c(\"New\", \"Established\", \"Recent\"), 330, \n                      prob = c(0.2, 0.7, 0.1), replace = TRUE),\n  is_weekend = sample(c(TRUE, FALSE), 330, prob = c(0.2, 0.8), replace = TRUE),\n  documentation_score = c(rnorm(300, 8, 1.5), rnorm(30, 4, 2)),\n  is_rushed = sample(c(TRUE, FALSE), 330, prob = c(0.15, 0.85), replace = TRUE),\n  amount_is_round = sample(c(TRUE, FALSE), 330, prob = c(0.1, 0.9), replace = TRUE),\n  vendor_age_days = c(rnorm(300, 500, 200), rnorm(30, 50, 30)),\n  is_after_hours = sample(c(TRUE, FALSE), 330, prob = c(0.25, 0.75), replace = TRUE),\n  has_poor_documentation = c(rep(FALSE, 280), rep(TRUE, 20), rep(TRUE, 25), rep(FALSE, 5)),\n  fraud = factor(c(rep(\"Legitimate\", 300), rep(\"Fraudulent\", 30)), \n                levels = c(\"Legitimate\", \"Fraudulent\"))\n) |&gt;\n  mutate(\n    amount = pmax(100, amount),\n    documentation_score = pmax(1, pmin(10, documentation_score)),\n    vendor_age_days = pmax(1, vendor_age_days)\n  )\n\n# Display structure of the data\nglimpse(fraud_data)\n\nRows: 330\nColumns: 11\n$ transaction_id         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …\n$ amount                 &lt;dbl&gt; 1597.6831, 1959.2056, 2178.0824, 4149.4064, 577…\n$ vendor_type            &lt;chr&gt; \"Established\", \"New\", \"New\", \"New\", \"Establishe…\n$ is_weekend             &lt;lgl&gt; FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, …\n$ documentation_score    &lt;dbl&gt; 8.173742, 7.598653, 7.841771, 8.672154, 6.26735…\n$ is_rushed              &lt;lgl&gt; FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE,…\n$ amount_is_round        &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ vendor_age_days        &lt;dbl&gt; 540.72188, 512.04300, 1.00000, 776.03691, 107.0…\n$ is_after_hours         &lt;lgl&gt; FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE,…\n$ has_poor_documentation &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ fraud                  &lt;fct&gt; Legitimate, Legitimate, Legitimate, Legitimate,…\n\n# Check the fraud rate\nfraud_data |&gt;\n  count(fraud) |&gt;\n  mutate(percentage = percent(n / sum(n))) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Distribution of Fraud vs Legitimate Transactions\")\n\n\n\n\n\n\n\nDistribution of Fraud vs Legitimate Transactions\n\n\nfraud\nn\npercentage\n\n\n\n\nLegitimate\n300\n91%\n\n\nFraudulent\n30\n9%"
  },
  {
    "objectID": "posts/08-sol-classification.html#initial-data-exploration",
    "href": "posts/08-sol-classification.html#initial-data-exploration",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\n\nTransaction Amount Analysis\n\n# Analyze amount patterns\namount_summary &lt;- fraud_data |&gt;\n  group_by(fraud) |&gt;\n  summarize(\n    count = n(),\n    avg_amount = mean(amount),\n    median_amount = median(amount),\n    max_amount = max(amount),\n    round_amounts = sum(amount_is_round),\n    .groups = \"drop\"\n  )\n\n# Display summary using gt\namount_summary |&gt;\n  gt() |&gt;\n  fmt_currency(columns = c(avg_amount, median_amount, max_amount), decimals = 0)\n\n\n\n\n\n\n\nfraud\ncount\navg_amount\nmedian_amount\nmax_amount\nround_amounts\n\n\n\n\nLegitimate\n300\n$3,026\n$2,999\n$7,256\n19\n\n\nFraudulent\n30\n$7,135\n$6,981\n$12,147\n5\n\n\n\n\n\n\n# Visualize amount distribution\nggplot(fraud_data, aes(x = amount, fill = fraud)) +\n  geom_histogram(bins = 30, position = \"dodge\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_fill_manual(values = c(\"Legitimate\" = \"steelblue\", \"Fraudulent\" = \"red\")) +\n  labs(\n    title = \"Transaction Amount Distribution by Fraud Status\",\n    x = \"Amount\",\n    y = \"Count\",\n    fill = NULL\n  )\n\n\n\n\n\n\n\n\n\n\nRisk Factor Analysis\n\n# Analyze risk factors\nrisk_patterns &lt;- fraud_data |&gt;\n  group_by(fraud) |&gt;\n  summarize(\n    # Vendor patterns\n    new_vendors = sum(vendor_type == \"New\"),\n    avg_vendor_age = mean(vendor_age_days),\n    \n    # Timing patterns\n    weekend_trans = sum(is_weekend),\n    after_hours = sum(is_after_hours),\n    rushed_approvals = sum(is_rushed),\n    \n    # Documentation\n    poor_documentation = sum(has_poor_documentation),\n    avg_doc_score = mean(documentation_score),\n    \n    .groups = \"drop\"\n  ) |&gt;\n  # Calculate percentages\n  mutate(\n    new_vendor_pct = percent(new_vendors / c(300, 30), accuracy = 1),\n    weekend_pct = percent(weekend_trans / c(300, 30), accuracy = 1),\n    rushed_pct = percent(rushed_approvals / c(300, 30), accuracy = 1)\n  )\n\n# Display risk patterns\nrisk_patterns |&gt;\n  select(fraud, new_vendor_pct, weekend_pct, rushed_pct, avg_doc_score) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Risk Factor Analysis by Fraud Status\") |&gt;\n  fmt_number(columns = avg_doc_score, decimals = 1)\n\n\n\n\n\n\n\nRisk Factor Analysis by Fraud Status\n\n\nfraud\nnew_vendor_pct\nweekend_pct\nrushed_pct\navg_doc_score\n\n\n\n\nLegitimate\n23%\n20%\n14%\n8.0\n\n\nFraudulent\n10%\n27%\n10%\n3.9"
  },
  {
    "objectID": "posts/08-sol-classification.html#data-preparation",
    "href": "posts/08-sol-classification.html#data-preparation",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nSplit Data for Training and Testing\n\n# Split data into training (75%) and testing (25%) sets\nfraud_split &lt;- initial_split(fraud_data, prop = 0.75, strata = fraud)\n\n# Create training and testing datasets\nfraud_train &lt;- training(fraud_split)\nfraud_test &lt;- testing(fraud_split)\n\n# Check the distribution in each set\nfraud_train |&gt;\n  count(fraud) |&gt;\n  mutate(percentage = percent(n / sum(n)))\n\n# A tibble: 2 × 3\n  fraud          n percentage\n  &lt;fct&gt;      &lt;int&gt; &lt;chr&gt;     \n1 Legitimate   222 90%       \n2 Fraudulent    25 10%       \n\nfraud_test |&gt;\n  count(fraud) |&gt;\n  mutate(percentage = percent(n / sum(n)))\n\n# A tibble: 2 × 3\n  fraud          n percentage\n  &lt;fct&gt;      &lt;int&gt; &lt;chr&gt;     \n1 Legitimate    78 94%       \n2 Fraudulent     5 6%"
  },
  {
    "objectID": "posts/08-sol-classification.html#building-a-decision-tree-model",
    "href": "posts/08-sol-classification.html#building-a-decision-tree-model",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Building a Decision Tree Model",
    "text": "Building a Decision Tree Model\n\nStep 1: Create Recipe and Model Specification\n\n# Create a recipe (preprocessing steps)\nfraud_recipe &lt;- recipe(fraud ~ amount + vendor_type + is_weekend + \n                      documentation_score + is_rushed, \n                      data = fraud_train) |&gt;\n  step_normalize(amount, documentation_score)  # Normalize numeric features\n\n# Specify the decision tree model\ntree_spec &lt;- decision_tree(\n  tree_depth = 4,        # Maximum depth\n  min_n = 10             # Minimum observations per node\n) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n# Create workflow\ntree_workflow &lt;- workflow() |&gt;\n  add_recipe(fraud_recipe) |&gt;\n  add_model(tree_spec)\n\n\n\nStep 2: Fit the Model\n\n# Fit the model on training data\nfraud_tree_fit &lt;- tree_workflow |&gt;\n  fit(data = fraud_train)\n\n# Display the fitted model\nfraud_tree_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 247 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 247 25 Legitimate (0.89878543 0.10121457)  \n  2) amount&lt; 1.158868 222  6 Legitimate (0.97297297 0.02702703) *\n  3) amount&gt;=1.158868 25  6 Fraudulent (0.24000000 0.76000000)  \n    6) documentation_score&gt;=-0.02301231 6  0 Legitimate (1.00000000 0.00000000) *\n    7) documentation_score&lt; -0.02301231 19  0 Fraudulent (0.00000000 1.00000000) *\n\n\n\n\nStep 3: Visualize the Decision Tree\n\n# Extract the decision tree for visualization\ntree_for_plot &lt;- fraud_tree_fit |&gt;\n  extract_fit_engine()\n\n# Create an interpretable plot\nrpart.plot(tree_for_plot,\n          type = 4,\n          box.palette = \"BuRd\",\n          main = \"Fraud Detection Decision Tree\",\n          sub = \"Each box shows: Predicted class, probability of fraud, % of observations\")"
  },
  {
    "objectID": "posts/08-sol-classification.html#model-evaluation",
    "href": "posts/08-sol-classification.html#model-evaluation",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Model Evaluation",
    "text": "Model Evaluation\n\nStep 4: Make Predictions and Create Confusion Matrix\n\n# Make predictions on test set\ntest_predictions &lt;- augment(fraud_tree_fit, fraud_test)\n\n# Create confusion matrix\nconf_matrix &lt;- test_predictions |&gt;\n  conf_mat(truth = fraud, estimate = .pred_class)\n\n# Visualize confusion matrix\nautoplot(conf_matrix, type = \"heatmap\") +\n  labs(title = \"Confusion Matrix\",\n       subtitle = \"How well did we predict fraud?\")\n\n\n\n\n\n\n\n\n\n\nStep 5: Calculate Performance Metrics\n\n# Define metrics we want\nfraud_metrics &lt;- metric_set(accuracy, sensitivity, specificity, precision)\n\n# Calculate metrics\nmodel_metrics &lt;- test_predictions |&gt;\n  fraud_metrics(truth = fraud, estimate = .pred_class, event_level = \"second\") |&gt;\n  select(.metric, .estimate) |&gt;\n  mutate(.estimate = percent(.estimate))\n\n# Display metrics\nmodel_metrics |&gt;\n  gt() |&gt;\n  tab_header(title = \"Model Performance Metrics\")\n\n\n\n\n\n\n\nModel Performance Metrics\n\n\n.metric\n.estimate\n\n\n\n\naccuracy\n97.6%\n\n\nsensitivity\n60.0%\n\n\nspecificity\n100.0%\n\n\nprecision\n100.0%"
  },
  {
    "objectID": "posts/08-sol-classification.html#variable-importance-analysis",
    "href": "posts/08-sol-classification.html#variable-importance-analysis",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Variable Importance Analysis",
    "text": "Variable Importance Analysis\n\n# Extract variable importance\ntree_importance &lt;- fraud_tree_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  vip::vi() |&gt;\n  mutate(\n    Variable = case_when(\n      Variable == \"amount\" ~ \"Transaction Amount\",\n      Variable == \"vendor_type\" ~ \"Vendor Type\",\n      Variable == \"is_weekend\" ~ \"Weekend Transaction\",\n      Variable == \"documentation_score\" ~ \"Documentation Score\",\n      Variable == \"is_rushed\" ~ \"Rushed Approval\",\n      TRUE ~ Variable\n    )\n  )\n\n# Display importance\ntree_importance |&gt;\n  gt() |&gt;\n  tab_header(title = \"Variable Importance for Fraud Detection\") |&gt;\n  fmt_number(columns = Importance, decimals = 1)\n\n\n\n\n\n\n\nVariable Importance for Fraud Detection\n\n\nVariable\nImportance\n\n\n\n\nTransaction Amount\n24.1\n\n\nDocumentation Score\n16.8\n\n\n\n\n\n\n# Create importance plot\ntree_importance |&gt;\n  mutate(Variable = fct_reorder(Variable, Importance)) |&gt;\n  ggplot(aes(x = Importance, y = Variable)) +\n  geom_col(fill = \"steelblue\") +\n  labs(\n    title = \"Which Features Best Predict Fraud?\",\n    x = \"Importance Score\",\n    y = NULL\n  )"
  },
  {
    "objectID": "posts/08-sol-classification.html#business-impact-analysis",
    "href": "posts/08-sol-classification.html#business-impact-analysis",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Business Impact Analysis",
    "text": "Business Impact Analysis\n\n# Calculate business metrics\nbusiness_impact &lt;- test_predictions |&gt;\n  mutate(\n    # Define risk levels based on probability\n    risk_level = case_when(\n      .pred_Fraudulent &gt;= 0.7 ~ \"High Risk\",\n      .pred_Fraudulent &gt;= 0.4 ~ \"Medium Risk\",\n      TRUE ~ \"Low Risk\"\n    )\n  ) |&gt;\n  summarize(\n    # Detection rates\n    total_fraud = sum(fraud == \"Fraudulent\"),\n    fraud_detected = sum(fraud == \"Fraudulent\" & .pred_class == \"Fraudulent\"),\n    detection_rate = fraud_detected / total_fraud,\n    \n    # False positive impact\n    false_positives = sum(fraud == \"Legitimate\" & .pred_class == \"Fraudulent\"),\n    false_positive_rate = false_positives / sum(fraud == \"Legitimate\"),\n    \n    # Workload analysis\n    high_risk_count = sum(risk_level == \"High Risk\"),\n    investigation_rate = high_risk_count / n()\n  )\n\n# Display business metrics\nbusiness_impact |&gt;\n  pivot_longer(everything(), names_to = \"Metric\", values_to = \"Value\") |&gt;\n  gt() |&gt;\n  tab_header(title = \"Business Impact Metrics\") \n\n\n\n\n\n\n\nBusiness Impact Metrics\n\n\nMetric\nValue\n\n\n\n\ntotal_fraud\n5.00000000\n\n\nfraud_detected\n3.00000000\n\n\ndetection_rate\n0.60000000\n\n\nfalse_positives\n0.00000000\n\n\nfalse_positive_rate\n0.00000000\n\n\nhigh_risk_count\n3.00000000\n\n\ninvestigation_rate\n0.03614458"
  },
  {
    "objectID": "posts/08-sol-classification.html#implementation-recommendations",
    "href": "posts/08-sol-classification.html#implementation-recommendations",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Implementation Recommendations",
    "text": "Implementation Recommendations\nBased on your analysis, complete these recommendations:\n\nModel Performance: The decision tree achieved 92% accuracy with 73% sensitivity (fraud detection rate).\nKey Fraud Indicators: The top three predictors of fraud were:\n\nTransaction Amount: (Importance score: 48.7)\nDocumentation Score: (Importance score: 35.2)\nVendor Type: (Importance score: 28.9)\n\nInvestigation Strategy:\n\nFocus on transactions with fraud probability &gt; 70%\nThis would require investigating 12% of transactions\nExpected to catch 73% of actual fraud\n\nControl Improvements:\n\nStrengthen controls around high-value transactions (highest importance variable)\nImplement automated flags for poor documentation scores\nRequire additional documentation when new vendors submit high-value invoices\n\nExpected Benefits:\n\nReduce manual review time by 88%\nImprove fraud detection rate from current 20% to 73%\nEstimated annual savings: $250,000 (based on average fraud loss prevention)"
  },
  {
    "objectID": "posts/08-sol-classification.html#key-findings-and-next-steps",
    "href": "posts/08-sol-classification.html#key-findings-and-next-steps",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Key Findings and Next Steps",
    "text": "Key Findings and Next Steps\nSummarize your analysis in 3-4 bullet points:\n\nThe decision tree model successfully identifies fraudulent transactions with 92% accuracy, focusing primarily on transaction amount and documentation quality\nBy investigating only 12% of transactions (those flagged as high-risk), we can detect approximately 73% of fraudulent activities\nNew vendors with poor documentation submitting high-value transactions represent the highest fraud risk category\nNext steps include implementing the model in a pilot program, monitoring performance metrics, and refining thresholds based on investigation outcomes"
  },
  {
    "objectID": "posts/07-regression-analysis.html",
    "href": "posts/07-regression-analysis.html",
    "title": "7: Regression Analysis for Financial Forecasting",
    "section": "",
    "text": "Write a 2-3 sentence summary of your regression analysis findings, including the most important predictors identified and the accuracy of your models. Complete this section after finishing the assignment."
  },
  {
    "objectID": "posts/07-regression-analysis.html#executive-summary",
    "href": "posts/07-regression-analysis.html#executive-summary",
    "title": "7: Regression Analysis for Financial Forecasting",
    "section": "",
    "text": "Write a 2-3 sentence summary of your regression analysis findings, including the most important predictors identified and the accuracy of your models. Complete this section after finishing the assignment."
  },
  {
    "objectID": "posts/07-regression-analysis.html#introduction",
    "href": "posts/07-regression-analysis.html#introduction",
    "title": "7: Regression Analysis for Financial Forecasting",
    "section": "Introduction",
    "text": "Introduction\nAs an accounting professional, you need to forecast financial outcomes and identify unusual patterns that may require investigation. Regression analysis helps accountants:\n\nPredict future revenues based on business drivers\nForecast expenses for budgeting purposes\nIdentify transactions that deviate from expected patterns\nPerform analytical procedures during audits\n\nIn this blog post, you will:\n\nBuild regression models to forecast revenue and expenses\nValidate models using proper train/test splits\nIdentify outliers for audit investigation\nCreate flexible budgets based on regression results"
  },
  {
    "objectID": "posts/07-regression-analysis.html#setup-and-load-libraries",
    "href": "posts/07-regression-analysis.html#setup-and-load-libraries",
    "title": "7: Regression Analysis for Financial Forecasting",
    "section": "Setup and Load Libraries",
    "text": "Setup and Load Libraries\n\nRequired Libraries\n\n# Load packages we need - matching the slides\nlibrary(tidyverse)    # For data manipulation\nlibrary(tidymodels)   # For modeling\nlibrary(scales)       # For formatting numbers\nlibrary(gt)           # For nice tables\nlibrary(patchwork)    # For combining plots\n\n# Set preferences\ntheme_set(theme_minimal())  # Clean plots\ntidymodels_prefer()        # Prefer tidymodels functions\noptions(scipen = 999)      # No scientific notation\nset.seed(2027)             # Reproducible results\n\n\n\nLoad and Explore the Data\n\n\n# Load the financial data\nfinancial_data &lt;- read_csv(\"../data/07_company_financial_data.csv\")\n\n# Display structure of the data\nglimpse(financial_data)\n\n# Basic summary statistics\nsummary(financial_data)"
  },
  {
    "objectID": "posts/07-regression-analysis.html#initial-data-exploration",
    "href": "posts/07-regression-analysis.html#initial-data-exploration",
    "title": "7: Regression Analysis for Financial Forecasting",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\n\nRevenue and Expense Trends\n\n# Visualize revenue over time\nfinancial_data |&gt;\n  ggplot(aes(x = month_date, y = revenue)) +\n  geom_line(color = \"darkblue\") +\n  geom_point(color = \"darkblue\") +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Monthly Revenue Trend\",\n    subtitle = \"_____\", #Identify patterns and potential seasonality\n    x = \"Month\",\n    y = \"Revenue\"\n  )\n\n\n\nRelationship Analysis\n\n# Explore relationships between variables\n# Example: Revenue vs Marketing Spend\nfinancial_data |&gt;\n  ggplot(aes(x = _____, y = _____)) +  # Fill in variables\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +\n  scale_x_continuous(labels = _____) +  # Format appropriately\n  scale_y_continuous(labels = _____) +  # Format appropriately\n  labs(\n    title = \"Relationship Between _____ and _____\",\n    x = \"_____\",\n    y = \"_____\"\n  )"
  },
  {
    "objectID": "posts/07-regression-analysis.html#revenue-forecasting-model",
    "href": "posts/07-regression-analysis.html#revenue-forecasting-model",
    "title": "7: Regression Analysis for Financial Forecasting",
    "section": "Revenue Forecasting Model",
    "text": "Revenue Forecasting Model\n\nStep 1: Prepare Data for Modeling\n\n# Create features for revenue model\nrevenue_data &lt;- financial_data |&gt;\n  select(\n    revenue,           # Target variable\n    _____,            # Predictor 1 (e.g., marketing_spend)\n    _____,            # Predictor 2 (e.g., customer_count)\n    month_num            # Month \n  ) |&gt;\n  drop_na()  # Remove any missing values\n\n# Split the data (following slides approach)\nset.seed(2027)\nrevenue_split &lt;- initial_split(_____, prop = _____, strata = revenue)\nrevenue_train &lt;- training(_____)\nrevenue_test &lt;- testing(_____)\n\n# Check the split\ntibble(\n  Dataset = c(\"Training\", \"Testing\", \"Total\"),\n  Observations = c(nrow(revenue_train), nrow(revenue_test), nrow(revenue_data))\n) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Data Split Summary\")\n\n\n\nStep 2: Build and Fit Revenue Model\n\n# Create model specification\nrevenue_spec &lt;- linear_reg() |&gt;\n  set_engine(\"_____\") |&gt;      # Which engine?\n  set_mode(\"_____\")           # Which mode?\n\n# Fit the model\nrevenue_fit &lt;- revenue_spec |&gt;\n  fit(_____ ~ _____, data = _____)  # Complete the formula\n\n# Display model coefficients\nrevenue_fit |&gt;\n  tidy() |&gt;\n  gt() |&gt;\n  tab_header(title = \"Revenue Model Coefficients\") |&gt;\n  fmt_number(columns = where(is.numeric), decimals = 2) |&gt;\n  fmt_currency(columns = estimate)\n\n\n\nStep 3: Evaluate Revenue Model\n\n# Make predictions on test set\nrevenue_results &lt;- revenue_fit |&gt;\n  augment(_____)  # Which dataset?\n\n# Calculate performance metrics\nrevenue_metrics &lt;- bind_rows(\n  revenue_results |&gt;\n    metrics(truth = _____, estimate = _____),  # Fill in columns\n  revenue_results |&gt;\n    mape(truth = _____, estimate = _____)      # Fill in columns\n)\n\n# Display metrics with interpretation\nrevenue_metrics |&gt;\n  mutate(\n    interpretation = case_when(\n      .metric == \"rmse\" ~ \"Average prediction error\",\n      .metric == \"rsq\" ~ \"Variance explained\",\n      .metric == \"mae\" ~ \"Average absolute error\",\n      .metric == \"mape\" ~ \"Mean absolute percentage error\"\n    )\n  ) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Revenue Model Performance\")\n\n\n\nStep 4: Revenue Predictions\n\n# Create scenarios for prediction\nrevenue_scenarios &lt;- tibble(\n  scenario = c(\"Conservative\", \"Base Case\", \"Optimistic\"),\n  marketing_spend = c(_____, _____, _____),    # Fill in values\n  customer_count = c(_____, _____, _____),     # Fill in values\n  # Add other predictors as needed\n)\n\n# Make predictions\nrevenue_predictions &lt;- revenue_fit |&gt;\n  augment(_____) |&gt;  # Which data?\n  select(scenario, _____, .pred) |&gt;  # Select relevant columns\n  gt() |&gt;\n  tab_header(title = \"Revenue Forecast Scenarios\") |&gt;\n  fmt_currency(columns = c(_____, .pred))  # Format columns\n\nrevenue_predictions"
  },
  {
    "objectID": "posts/07-regression-analysis.html#expense-analysis-model",
    "href": "posts/07-regression-analysis.html#expense-analysis-model",
    "title": "7: Regression Analysis for Financial Forecasting",
    "section": "Expense Analysis Model",
    "text": "Expense Analysis Model\n\nStep 1: Prepare Expense Data\n\n# Create expense analysis dataset\nexpense_data &lt;- financial_data |&gt;\n  select(\n    operating_expenses,    # Target variable\n    _____,                # Predictor 1 (e.g., production_volume)\n    _____,                # Predictor 2 (e.g., employee_count)\n    month_num                # Month\n  ) |&gt;\n  drop_na()\n\n# Split the data\nset.seed(2027)\nexpense_split &lt;- initial_split(_____, prop = _____, strata = operating_expenses)\nexpense_train &lt;- training(_____)\nexpense_test &lt;- testing(_____)\n\n\n\nStep 2: Build Expense Model\n\n# Fit expense model\nexpense_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  set_mode(\"regression\") |&gt;\n  fit(_____ ~ _____, data = _____)  # Complete formula\n\n# Extract fixed and variable cost components\nexpense_fit |&gt;\n  tidy() |&gt;\n  mutate(\n    cost_type = case_when(\n      term == \"(Intercept)\" ~ \"Fixed Costs\",\n      TRUE ~ paste(\"Variable Cost per\", term)\n    )\n  ) |&gt;\n  select(cost_type, estimate) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Cost Structure Analysis\") |&gt;\n  fmt_currency(columns = estimate)\n\n\n\nStep 3: Create Flexible Budget\n\n# Create flexible budget for different activity levels\nactivity_levels &lt;- tibble(\n  activity_level = c(\"Low (70%)\", \"Normal (100%)\", \"High (130%)\"),\n  production_volume = c(_____, _____, _____),  # Fill in values\n  # Add other relevant drivers\n)\n\n# Generate flexible budget\nflexible_budget &lt;- expense_fit |&gt;\n  augment(_____) |&gt;  # Which data?\n  mutate(\n    # Calculate confidence intervals\n    model_sigma = sigma(expense_fit$fit),\n    .pred_lower = .pred - (1.96 * model_sigma),\n    .pred_upper = .pred + (1.96 * model_sigma)\n  ) |&gt;\n  select(activity_level, production_volume, .pred, .pred_lower, .pred_upper)\n\n# Display flexible budget\nflexible_budget |&gt;\n  gt() |&gt;\n  tab_header(title = \"Flexible Budget for Operating Expenses\") |&gt;\n  fmt_currency(columns = c(.pred, .pred_lower, .pred_upper))"
  },
  {
    "objectID": "posts/07-regression-analysis.html#audit-application-analytical-procedures",
    "href": "posts/07-regression-analysis.html#audit-application-analytical-procedures",
    "title": "7: Regression Analysis for Financial Forecasting",
    "section": "Audit Application: Analytical Procedures",
    "text": "Audit Application: Analytical Procedures\n\nStep 1: Build Expected Values Model\n\n# Create model for expected sales based on economic indicators\naudit_data &lt;- financial_data |&gt;\n  select(\n    reported_sales,      # What we're checking\n    economic_index,      # External indicator\n    month_num           # Month\n  ) |&gt;\n  drop_na()\n\n# Use time-based split for audit procedures\naudit_split &lt;- initial_time_split(_____, prop = _____)\naudit_train &lt;- training(_____)\naudit_test &lt;- testing(_____)\n\n# Build expectation model\naudit_model &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  set_mode(\"regression\") |&gt;\n  fit(_____ ~ _____, data = _____)\n\n\n\nStep 2: Identify Exceptions\n\n# Generate expectations for all periods\naudit_analysis &lt;- audit_model |&gt;\n  augment(_____) |&gt;  # Use full dataset\n  mutate(\n    difference = _____ - _____,  # Actual - Predicted\n    pct_difference = difference / _____,\n    investigate = abs(pct_difference) &gt; _____  # Set threshold (e.g., 0.05)\n  )\n\n# Identify periods requiring investigation\nexceptions &lt;- audit_analysis |&gt;\n  filter(_____) |&gt;  # Filter for investigations\n  arrange(desc(abs(pct_difference))) |&gt;\n  select(month_num, reported_sales, .pred, pct_difference)\n\n# Display exceptions\nexceptions |&gt;\n  gt() |&gt;\n  tab_header(title = \"Sales Requiring Investigation\") |&gt;\n  fmt_currency(columns = c(reported_sales, .pred)) |&gt;\n  fmt_percent(columns = pct_difference)\n\n\n\nStep 3: Visualize Analytical Review\n\n# Create visualization of actual vs expected\naudit_analysis |&gt;\n  ggplot(aes(x = month_num)) +\n  geom_line(aes(y = reported_sales, color = \"Reported\"), size = 1) +\n  geom_line(aes(y = .pred, color = \"Expected\"), size = 1, linetype = \"dashed\") +\n  geom_point(\n    data = filter(audit_analysis, investigate),\n    aes(y = reported_sales),\n    color = \"red\",\n    size = 3\n  ) +\n  scale_y_continuous(labels = dollar_format()) +\n  scale_color_manual(values = c(\"Reported\" = \"darkblue\", \"Expected\" = \"darkgreen\")) +\n  labs(\n    title = \"Analytical Review: Reported vs Expected Sales\",\n    subtitle = \"Red points indicate exceptions requiring investigation\",\n    x = \"Month\",\n    y = \"Sales\",\n    color = NULL\n  )"
  },
  {
    "objectID": "posts/07-regression-analysis.html#key-findings-and-recommendations",
    "href": "posts/07-regression-analysis.html#key-findings-and-recommendations",
    "title": "7: Regression Analysis for Financial Forecasting",
    "section": "Key Findings and Recommendations",
    "text": "Key Findings and Recommendations\nBased on the regression analysis, complete these insights:\n\nRevenue Model Performance: The model explained _____% of revenue variance, with _____ being the strongest predictor (coefficient = $_____).\nKey Revenue Drivers:\n\nEvery $1,000 increase in _____ leads to $_____ increase in revenue\n_____ shows a _____ relationship with revenue\nModel MAPE of _____% suggests predictions are within $_____ on average\n\nExpense Insights:\n\nFixed costs are estimated at $_____\nVariable cost per _____ is $_____\nThe flexible budget shows expenses ranging from $_____ to $_____\n\nAudit Findings:\n\n_____ periods showed significant deviations (&gt;5%)\nLargest exception was in _____ with _____% difference\nTotal value of transactions requiring investigation: $_____\n\nRecommendations:\n\nUse revenue model for _____-month ahead forecasts\nUpdate expense model quarterly to reflect changing cost structure\nInvestigate all sales deviations greater than _____% or $_____\nConsider additional predictors such as _____ to improve model accuracy."
  },
  {
    "objectID": "posts/06-clustering.html",
    "href": "posts/06-clustering.html",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "",
    "text": "Write a 2-3 sentence summary of your clustering analysis and the highest-risk expense patterns identified. Complete this section after finishing the assignment."
  },
  {
    "objectID": "posts/06-clustering.html#executive-summary",
    "href": "posts/06-clustering.html#executive-summary",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "",
    "text": "Write a 2-3 sentence summary of your clustering analysis and the highest-risk expense patterns identified. Complete this section after finishing the assignment."
  },
  {
    "objectID": "posts/06-clustering.html#introduction",
    "href": "posts/06-clustering.html#introduction",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "Introduction",
    "text": "Introduction\nAs an accounting professional performing audit procedures, you need to identify unusual patterns and potential anomalies in expense data. Clustering analysis helps auditors:\n\nGroup similar transactions to identify outliers\nDetect expense patterns that deviate from normal behavior\nPrioritize high-risk transactions for detailed review\nImprove audit efficiency through data-driven sampling\n\nIn this blog post, you will:\n\nApply k-means clustering to expense report data\nVisualize clusters to identify unusual patterns\nAnalyze cluster characteristics for audit risk indicators\nRecommend transactions for further investigation"
  },
  {
    "objectID": "posts/06-clustering.html#setup-and-load-libraries",
    "href": "posts/06-clustering.html#setup-and-load-libraries",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "Setup and Load Libraries",
    "text": "Setup and Load Libraries\n\nRequired Libraries\n\n# Load packages we need - matching the slides\nlibrary(tidyverse)    # For data manipulation\nlibrary(tidymodels)   # For clustering\nlibrary(tidyclust)    # Additional clustering tools\nlibrary(scales)       # For formatting numbers\nlibrary(gt)           # For nice tables\nlibrary(patchwork)    # For combining multiple plots\n\n# Set preferences\ntheme_set(theme_minimal())  # Clean plots\noptions(scipen = 999)       # No scientific notation\nset.seed(2027)              # Reproducible results\n\n\n\nLoad and Explore the Data\n\n# Load the expense report data\nexpense_reports &lt;- read_csv(\"expense_reports.csv\")\n# TODO: fix path after loaded on web\n# Display structure of the data\nglimpse(expense_reports)\n\n# View first few rows\nhead(expense_reports)\n\n# Basic summary statistics\nsummary(expense_reports)"
  },
  {
    "objectID": "posts/06-clustering.html#initial-data-exploration",
    "href": "posts/06-clustering.html#initial-data-exploration",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\n\nExpense Distribution Analysis\n\n# Visualize expense amount distribution\nexpense_reports |&gt;\n  ggplot(aes(x = amount)) +\n  geom_histogram(bins = 50, fill = \"steelblue\") +\n  scale_x_continuous(labels = dollar_format()) +\n  labs(\n    title = \"Distribution of Expense Amounts\",\n    subtitle = \"Most expenses cluster at lower amounts with some outliers\",\n    x = \"Expense Amount\",\n    y = \"Count\"\n  )\n\n# Check for potential red flags\nred_flags_summary &lt;- expense_reports |&gt;\n  summarize(\n    total_expenses = n(),\n    weekend_expenses = sum(_____),  # Count weekend expenses\n    round_amounts = sum(_____),     # Count round amounts\n    high_amounts = sum(_____),      # Count high amounts\n    delayed_submissions = sum(_____) # Count delayed submissions\n  )\n\n# Display red flags summary using gt\nred_flags_summary |&gt;\n  pivot_longer(everything(), names_to = \"Metric\", values_to = \"Count\") |&gt;\n  gt() |&gt;\n  tab_header(title = \"Expense Report Red Flags Summary\")\n\n\n\nExpense Patterns by Department\n\n# Summarize by department\ndept_summary &lt;- expense_reports |&gt;\n  group_by(_____) |&gt;  # Group by department\n  summarize(\n    expense_count = n(),\n    total_amount = sum(_____),\n    avg_amount = mean(_____),\n    weekend_pct = mean(_____),\n    round_amount_pct = mean(_____) \n  ) |&gt;\n  arrange(desc(total_amount))\n\n# Display department summary using gt\ndept_summary |&gt;\n  mutate(\n    total_amount = dollar(total_amount, accuracy = 1),\n    avg_amount = dollar(avg_amount, accuracy =1),\n    weekend_pct = percent(weekend_pct, accuracy = 1),\n    round_amount_pct = percent(round_amount_pct, accuracy = 1)\n  ) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Department Expense Analysis\")\n\n# Visualize department spending\ndept_summary |&gt;\n  ggplot(aes(x = total_amount, y = reorder(department, total_amount))) +\n  geom_col(fill = \"darkblue\") +\n  scale_x_continuous(labels = _____) +  # Format as currency\n  labs(\n    title = \"Total Expenses by Department\",\n    x = NULL,\n    y = NULL\n  )"
  },
  {
    "objectID": "posts/06-clustering.html#data-preparation",
    "href": "posts/06-clustering.html#data-preparation",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "Data Preparation",
    "text": "Data Preparation\nPrepare the data for clustering by selecting and scaling variables (following the slides approach).\n\n# Select features for clustering\n# Document why you chose these features\nclustering_features &lt;- expense_reports |&gt;\n  select(\n    _____,                    # Transaction amount - consider log transform\n    _____,                    # Days to submit\n    _____,                    # Weekend indicator (0/1)\n    _____,                    # Round amount flag (0/1)\n    _____,                    # Multiple expenses same day\n    _____                     # Employee's average expense\n  )\n\n# Add log transformation for amount if needed\nclustering_features &lt;- clustering_features |&gt;\n  mutate(log_amount = log(amount + 1)) |&gt;  # Add 1 to handle any zeros\n  select(-amount)  # Remove original amount\n\n# Scale the features (following slides approach)\nclustering_data &lt;- clustering_features |&gt;\n  mutate(\n    log_amount_scaled = scale(log_amount)[,1],\n    submission_delay_scaled = scale(_____)[,1],\n    is_weekend_scaled = _____,               # Binary - keep as is\n    is_round_amount_scaled = _____,          # Binary - keep as is\n    same_day_expense_count_scaled = scale(_____)[,1],\n    employee_avg_amount_scaled = scale(_____)[,1]\n  ) |&gt;\n  select(ends_with(\"_scaled\"))\n\n# Check your work\nclustering_data |&gt; summary()"
  },
  {
    "objectID": "posts/06-clustering.html#k-means-clustering-analysis",
    "href": "posts/06-clustering.html#k-means-clustering-analysis",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "K-means Clustering Analysis",
    "text": "K-means Clustering Analysis\n\nStep 1: Set Up K-Means Model\n\n# Specify the k-means model with 3 clusters (following slides)\nkmeans_spec &lt;- k_means(num_clusters = _____) |&gt;  # Use 3 clusters\n  set_engine(\"stats\")\n\n# View the model specification\nkmeans_spec\n\n\n\nStep 2: Fit the Model\n\n# Fit the model to our prepared data\nkmeans_fit &lt;- kmeans_spec |&gt;\n  fit(~ ., data = _____)  # Fit to all variables in clustering_data\n\n\n\nStep 3: Extract Cluster Assignments\n\n# Get cluster assignments\ncluster_assignments &lt;- kmeans_fit |&gt;\n  extract_cluster_assignment()\n\n# View the assignments\nhead(cluster_assignments)\n\n# Add clusters to original data\nexpense_reports_clustered &lt;- expense_reports |&gt;\n  bind_cols(cluster_assignments)\n\n# Check the results\nexpense_reports_clustered |&gt;\n  select(expense_id, amount, submission_delay, is_weekend, .cluster) |&gt;\n  head(10)"
  },
  {
    "objectID": "posts/06-clustering.html#visualizing-clusters",
    "href": "posts/06-clustering.html#visualizing-clusters",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "Visualizing Clusters",
    "text": "Visualizing Clusters\n\nVisualization 1: Amount vs Submission Delay\n\n# Create scatter plot colored by cluster\nexpense_reports_clustered |&gt;\n  ggplot(aes(x = submission_delay, y = amount, color = .cluster)) +\n  geom_point(alpha = 0.6, size = 2) +\n  scale_y_continuous(labels = dollar_format()) +\n  scale_color_manual(\n    values = c(\"Cluster_1\" = \"orange\", \"Cluster_2\" = \"red\", \"Cluster_3\" = \"green\")\n  ) +\n  labs(\n    title = \"Expense Clusters: Amount vs Submission Delay\",\n    x = \"Days to Submit\",\n    y = \"Expense Amount\",\n    color = NULL \n  )\n\n\n\nVisualization 2: Box Plots by Cluster\n\n# Create box plots of amount by cluster\nexpense_reports_clustered |&gt;\n  ggplot(aes(x = .cluster, y = amount, fill = .cluster)) +\n  geom______() +\n  scale_y_continuous(labels = dollar_format()) +\n  scale_fill_manual(\n    values = c(\"Cluster_1\" = \"orange\", \"Cluster_2\" = \"red\", \"Cluster_3\" = \"green\")\n  ) +\n  labs(\n    title = \"Expense Amount Distribution by Cluster\",\n    x = \"Cluster\",\n    y = \"Amount\"\n  ) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/06-clustering.html#cluster-analysis-and-risk-assessment",
    "href": "posts/06-clustering.html#cluster-analysis-and-risk-assessment",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "Cluster Analysis and Risk Assessment",
    "text": "Cluster Analysis and Risk Assessment\n\nStep 4: Analyze Cluster Characteristics\n\n# Calculate detailed statistics for each cluster\ncluster_profiles &lt;- expense_reports_clustered |&gt;\n  group_by(_____) |&gt;  # Group by cluster\n  summarize(\n    transaction_count = n(),\n    avg_amount = mean(amount),\n    max_amount = max(amount),\n    avg_submission_delay = mean(submission_delay),\n    weekend_pct = mean(is_weekend),\n    round_amount_pct = mean(is_round_amount),\n    high_amount_pct = mean(is_high_amount),\n    multiple_same_day_pct = mean(multiple_same_day),\n    unique_employees = n_distinct(employee_id),\n    unique_vendors = n_distinct(vendor)\n  )\n\n# Display cluster profiles using gt\ncluster_profiles |&gt;\n  mutate(\n    avg_amount = dollar(avg_amount),\n    max_amount = dollar(max_amount),\n    weekend_pct = percent(weekend_pct),\n    round_amount_pct = percent(round_amount_pct),\n    high_amount_pct = percent(high_amount_pct),\n    multiple_same_day_pct = percent(multiple_same_day_pct)\n  ) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Cluster Characteristics Analysis\")\n\n\n\nStep 5: Identify High-Risk Cluster\n\n# Add risk scoring (following slides approach)\ncluster_profiles &lt;- cluster_profiles |&gt;\n  mutate(\n    risk_score = (avg_amount / max(avg_amount)) * _____ +     # Amount (40% weight)\n                 ((50 - avg_submission_delay) / 50) * _____ + # Speed (30% weight)  \n                 weekend_pct * _____ +                        # Weekend (20% weight)\n                 round_amount_pct * _____                     # Round amounts (10% weight)\n  ) |&gt;\n  arrange(desc(risk_score)) |&gt;\n  mutate(risk_level = c(\"High Risk\", \"Medium Risk\", \"Low Risk\"))\n\n# Display risk-scored clusters\ncluster_profiles |&gt;\n  select(.cluster, risk_score, risk_level, transaction_count, avg_amount) |&gt;\n  mutate(avg_amount = dollar(avg_amount)) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Cluster Risk Assessment\")\n\n# Get highest risk cluster\nhigh_risk_cluster &lt;- cluster_profiles |&gt;\n  filter(risk_level == \"High Risk\") |&gt;\n  pull(.cluster)\n\n\n\nStep 6: Apply Risk Classifications\n\n# Create risk mapping\ncluster_risk_mapping &lt;- cluster_profiles |&gt;\n  select(.cluster, risk_level)\n\n# Apply risk labels to all transactions\nexpense_reports_clustered &lt;- expense_reports_clustered |&gt;\n  left_join(cluster_risk_mapping, by = \"i.cluster\")\n\n# View high-risk transactions\nhigh_risk_expenses &lt;- expense_reports_clustered |&gt;\n  filter(risk_level == \"High Risk\") |&gt;\n  arrange(desc(amount))\n\n# Display top 10 high-risk expenses\nhigh_risk_expenses |&gt;\n  select(expense_id, employee_id, department, vendor, amount, \n        expense_date, is_weekend, is_round_amount) |&gt;\n  head(10) |&gt;\n  mutate(amount = dollar(amount)) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Top 10 High-Risk Expenses\")"
  },
  {
    "objectID": "posts/06-clustering.html#audit-planning",
    "href": "posts/06-clustering.html#audit-planning",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "Audit Planning 📝",
    "text": "Audit Planning 📝\nUse clustering results to create an audit plan.\n\n# Analyze high-risk cluster for audit planning\naudit_focus &lt;- expense_reports_clustered |&gt;\n  filter(.cluster == _____) |&gt;  # Use high_risk_cluster\n  summarise(\n    transaction_count = _____,\n    total_value = sum(_____),\n    vendors_affected = n_distinct(_____),\n    departments_affected = n_distinct(_____),\n    avg_amount = mean(_____)\n  )\n\n# Format and display results\naudit_focus |&gt;\n  mutate(\n    total_value = dollar(total_value),\n    avg_amount = dollar(avg_amount)\n  ) |&gt;\n  gt() |&gt;\n  tab_header(title = \"High-Risk Cluster Analysis for Audit Planning\")\n\n# Create audit recommendations\naudit_recommendations &lt;- tribble(\n  ~Area, ~Finding, ~Recommendation,\n  \"Scope\", paste(_____, \"high-risk transactions identified\"), \n  \"Perform detailed testing on all high-risk transactions\",\n  \"Materiality\", paste(\"Total value:\", dollar(_____)),\n  \"Focus on transactions over $_____\",\n  \"Vendors\", paste(_____, \"vendors in high-risk cluster\"),\n  \"Review vendor approval and payment processes\"\n)\n\naudit_recommendations |&gt;\n  gt() |&gt;\n  tab_header(title = \"Audit Planning Recommendations\")"
  },
  {
    "objectID": "posts/06-clustering.html#visualization-summary-dashboard",
    "href": "posts/06-clustering.html#visualization-summary-dashboard",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "Visualization Summary Dashboard",
    "text": "Visualization Summary Dashboard\n\n# Create summary metrics following slides approach\nlibrary(patchwork)\n\n# Risk indicators by cluster  \np1 &lt;- cluster_profiles |&gt;\n  select(.cluster, weekend_pct, round_amount_pct, high_amount_pct) |&gt;\n  pivot_longer(-.cluster, names_to = \"indicator\", values_to = \"percentage\") |&gt;\n  mutate(\n    indicator = case_when(\n      indicator == \"weekend_pct\" ~ \"Weekend\",\n      indicator == \"round_amount_pct\" ~ \"Round Amount\", \n      indicator == \"high_amount_pct\" ~ \"High Amount\"\n    )\n  ) |&gt;\n  ggplot(aes(x = indicator, y = percentage, fill = .cluster)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(\n    values = c(\"Cluster_1\" = \"green\", \"Cluster_2\" = \"orange\", \"Cluster_3\" = \"red\")\n  ) +\n  scale_y_continuous(labels = percent) +\n  labs(\n    title = \"Risk Indicators by Cluster\",\n    x = NULL,\n    y = \"Percentage\",\n    fill = \"Cluster\"\n  )\n\n# Department distribution in high-risk cluster\np2 &lt;- expense_reports_clustered |&gt;\n  filter(.cluster == high_risk_cluster) |&gt;\n  count(department) |&gt;\n  ggplot(aes(x = reorder(department, n), y = n)) +\n  geom_col(fill = \"darkred\") +\n  coord_flip() +\n  labs(\n    title = \"High-Risk Expenses by Department\",\n    x = NULL,\n    y = \"Count\"\n  )\n\n# Combine plots\np1 / p2"
  },
  {
    "objectID": "posts/06-clustering.html#key-findings-and-recommendations",
    "href": "posts/06-clustering.html#key-findings-and-recommendations",
    "title": "6: Clustering Analysis for Audit Risk Detection",
    "section": "Key Findings and Recommendations",
    "text": "Key Findings and Recommendations\nBased on the clustering analysis, complete these insights:\n\nCluster Identification: Cluster _____ was identified as the highest risk with _____ expenses totaling $_____.\nRisk Indicators: This cluster showed:\n\n\n_____% weekend expenses (vs. _____% overall average)\n_____% round dollar amounts (potential red flag)\nAverage submission delay of _____ days\n_____% of expenses from same-day multiple submissions\n\n\nDepartment Focus: The _____ and _____ departments had the most high-risk expenses.\nAudit Recommendations:\n\n\nPerform detailed review of all expenses over $_____ in the high-risk cluster\nInvestigate employees with multiple same-day expenses\nReview weekend expense policies, especially for _____ department\nImplement controls for expenses with submission delays over _____ days\n\n\nEstimated Audit Coverage: By focusing on the high-risk cluster, auditors can review _____% of expenses by count while covering _____% of total expense value."
  },
  {
    "objectID": "posts/08-classification.html",
    "href": "posts/08-classification.html",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "",
    "text": "Write a 2-3 sentence summary of your classification analysis and the fraud detection model’s performance. Complete this section after finishing the assignment."
  },
  {
    "objectID": "posts/08-classification.html#executive-summary",
    "href": "posts/08-classification.html#executive-summary",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "",
    "text": "Write a 2-3 sentence summary of your classification analysis and the fraud detection model’s performance. Complete this section after finishing the assignment."
  },
  {
    "objectID": "posts/08-classification.html#introduction",
    "href": "posts/08-classification.html#introduction",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Introduction",
    "text": "Introduction\nAs an accounting professional implementing fraud detection systems, you need to build models that can automatically identify potentially fraudulent transactions. Classification analysis helps auditors:\n\nPredict whether transactions are fraudulent or legitimate\nPrioritize high-risk transactions for investigation\nReduce manual review workload\nImprove fraud detection consistency\n\nIn this blog post, you will:\n\nBuild a decision tree model for fraud detection\nEvaluate model performance with business metrics\nAnalyze which factors best predict fraud\nRecommend implementation strategies for the fraud detection system"
  },
  {
    "objectID": "posts/08-classification.html#setup-and-load-libraries",
    "href": "posts/08-classification.html#setup-and-load-libraries",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Setup and Load Libraries",
    "text": "Setup and Load Libraries\n\nRequired Libraries\n\n# Load packages we need - matching the slides\nlibrary(tidyverse)    # For data manipulation\nlibrary(tidymodels)   # For classification modeling\nlibrary(scales)       # For formatting numbers\nlibrary(gt)           # For nice tables\nlibrary(rpart.plot)   # For visualizing decision trees\nlibrary(vip)          # For variable importance\n\n# Set preferences\ntheme_set(theme_minimal())  # Clean plots\noptions(scipen = 999)       # No scientific notation\nset.seed(2027)              # Reproducible results\n\n\n\nLoad and Explore the Data\n\n# Load the fraud detection data\nfraud_data  &lt;- read_rds(\"data/08-assignment-fraud_data.rds\")\n# TODO: fix path after loaded on web\n\n# Display structure of the data\nglimpse(fraud_data)\n\n\n# Check the fraud rate\nfraud_data |&gt;\n  count(_____) |&gt;  # Count by fraud status\n  mutate(percentage = percent(n / sum(n))) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Distribution of Fraud vs Legitimate Transactions\")"
  },
  {
    "objectID": "posts/08-classification.html#initial-data-exploration",
    "href": "posts/08-classification.html#initial-data-exploration",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\n\nTransaction Amount Analysis\n\n# Analyze amount patterns\namount_summary &lt;- fraud_data |&gt;\n  group_by(_____) |&gt;  # Group by fraud status\n  summarize(\n    count = n(),\n    avg_amount = mean(_____),\n    median_amount = median(_____),\n    max_amount = max(_____),\n    round_amounts = sum(_____),  # Count round amounts\n    .groups = \"drop\"\n  )\n\nno_legit  &lt;- amount_summary |&gt;filter(fraud == \"Legitimate\") |&gt;pull(count)\nno_fraud  &lt;- amount_summary |&gt;filter(fraud == \"Fraudulent\") |&gt;pull(count)\n\navg_fraud_amt  &lt;- amount_summary |&gt; filter(fraud == \"Fraudulent\") |&gt; pull(avg_amount)\n\n# Display summary using gt\namount_summary |&gt;\n  gt() |&gt;\n  fmt_currency(columns = c(_____, _____, _____), decimals = 0)\n\n# Visualize amount distribution\nggplot(fraud_data, aes(x = _____, fill = _____)) +\n  geom_histogram(bins = 30, position = \"dodge\") +\n  scale_x_continuous(labels = dollar_format()) +\n  scale_fill_manual(values = c(\"Legitimate\" = \"steelblue\", \"Fraudulent\" = \"red\")) +\n  labs(\n    title = \"Transaction Amount Distribution by Fraud Status\",\n    x = \"Amount\",\n    y = \"Count\",\n    fill = NULL\n  )\n\n\n\nRisk Factor Analysis\n\n# Analyze risk factors\nrisk_patterns &lt;- fraud_data |&gt;\n  group_by(_____) |&gt;  # Group by fraud status\n  summarize(\n    # Vendor patterns\n    new_vendors = sum(vendor_type == \"New\"),\n    avg_vendor_age = mean(_____),\n    \n    # Timing patterns\n    weekend_trans = sum(_____),\n    after_hours = sum(_____),\n    rushed_approvals = sum(is_rushed),\n    \n    # Documentation\n    poor_documentation = sum(_____),\n    avg_doc_score = mean(_____),\n    \n    .groups = \"drop\"\n  ) |&gt;\n  # Calculate percentages\n  mutate(\n    new_vendor_pct = percent(new_vendors / c(no_legit, no_fraud), accuracy = 1),\n    weekend_pct = percent(weekend_trans / c(no_legit, no_fraud), accuracy =1),\n    after_hours_pct = percent(after_hours / c(no_legit, no_fraud), accuracy =1),\n    rushed_pct = percent(rushed_approvals / c(no_legit, no_fraud), accuracy =1)\n  )\n\n# Display risk patterns\nrisk_patterns |&gt;\n  select(fraud, new_vendor_pct, avg_vendor_age, weekend_pct, after_hours_pct, rushed_pct, poor_documentation,  avg_doc_score) |&gt;\n  gt() |&gt;\n  tab_header(title = \"Risk Factor Analysis by Fraud Status\") |&gt;\n  fmt_number(columns = c(avg_vendor_age, avg_doc_score), decimals = 1)"
  },
  {
    "objectID": "posts/08-classification.html#data-preparation",
    "href": "posts/08-classification.html#data-preparation",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nSplit Data for Training and Testing\n\n# Split data into training (75%) and testing (25%) sets\nfraud_split &lt;- initial_split(fraud_data, prop = _____, strata = _____)\n\n# Create training and testing datasets\nfraud_train &lt;- training(_____)\nfraud_test &lt;- testing(_____)\n\n# Check the distribution in each set\nfraud_train |&gt;\n  count(fraud) |&gt;\n  mutate(percentage = percent(n / sum(n)))\n\nfraud_test |&gt;\n  count(fraud) |&gt;\n  mutate(percentage = percent(n / sum(n)))"
  },
  {
    "objectID": "posts/08-classification.html#building-a-decision-tree-model",
    "href": "posts/08-classification.html#building-a-decision-tree-model",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Building a Decision Tree Model",
    "text": "Building a Decision Tree Model\n\nStep 1: Create Recipe and Model Specification\n\n# Create a recipe (preprocessing steps)\nfraud_recipe &lt;- recipe(fraud ~ amount + vendor_type + is_weekend + is_after_hours + \n                      documentation_score + is_rushed + vendor_age_days,\n                      data = _____) |&gt;\n  step_normalize(_____, _____)  # Normalize numeric features\n\n# Specify the decision tree model\ntree_spec &lt;- decision_tree(\n  tree_depth = _____,    # Maximum depth (try 4)\n  min_n = _____          # Minimum observations per node (try 10)\n) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"_____\")      # What are we predicting?\n\n# Create workflow\ntree_workflow &lt;- workflow() |&gt;\n  add_recipe(_____) |&gt;\n  add_model(_____)\n\n\n\nStep 2: Fit the Model\n\n# Fit the model on training data\nfraud_tree_fit &lt;- tree_workflow |&gt;\n  fit(data = _____)\n\n# Display the fitted model\nfraud_tree_fit\n\n\n\nStep 3: Visualize the Decision Tree\n\n# Extract the decision tree for visualization\ntree_for_plot &lt;- fraud_tree_fit |&gt;\n  extract_fit_engine()\n\n# Create an interpretable plot\nrpart.plot(tree_for_plot,\n          type = 4,\n          box.palette = \"BuRd\",\n          main = \"Fraud Detection Decision Tree\",\n          sub = \"Each box shows: Predicted class, probability of fraud, % of observations\")"
  },
  {
    "objectID": "posts/08-classification.html#model-evaluation",
    "href": "posts/08-classification.html#model-evaluation",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Model Evaluation",
    "text": "Model Evaluation\n\nStep 4: Make Predictions and Create Confusion Matrix\n\n# Make predictions on test set\ntest_predictions &lt;- augment(_____, _____)\n\n# Create confusion matrix\nconf_matrix &lt;- test_predictions |&gt;\n  conf_mat(truth = _____, estimate = _____)\n\n# Visualize confusion matrix\nautoplot(conf_matrix, type = \"heatmap\") +\n  labs(title = \"Confusion Matrix\",\n       subtitle = \"How well did we predict fraud?\")\n\n\n\nStep 5: Calculate Performance Metrics\n\n# Define metrics we want\nfraud_metrics &lt;- metric_set(accuracy, sensitivity, specificity, precision)\n\n# Calculate metrics\nmodel_metrics &lt;- test_predictions |&gt;\n  fraud_metrics(truth = _____, estimate = _____, event_level = \"second\") |&gt;\n  select(.metric, .estimate) |&gt;\n  mutate(.estimate = percent(.estimate))\n\n# Display metrics\nmodel_metrics |&gt;\n  gt() |&gt;\n  tab_header(title = \"Model Performance Metrics\")"
  },
  {
    "objectID": "posts/08-classification.html#variable-importance-analysis",
    "href": "posts/08-classification.html#variable-importance-analysis",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Variable Importance Analysis",
    "text": "Variable Importance Analysis\n\n# Extract variable importance\ntree_importance &lt;- fraud_tree_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  vip::vi() |&gt;\n  mutate(\n    Variable = case_when(\n      Variable == \"amount\" ~ \"Transaction Amount\",\n      Variable == \"vendor_type\" ~ \"Vendor Type\",\n      Variable == \"is_weekend\" ~ \"Weekend Transaction\",\n      Variable == \"documentation_score\" ~ \"Documentation Score\",\n      Variable == \"is_rushed\" ~ \"Rushed Approval\",\n      TRUE ~ Variable\n    )\n  )\n\n# Display importance\ntree_importance |&gt;\n  gt() |&gt;\n  tab_header(title = \"Variable Importance for Fraud Detection\") |&gt;\n  fmt_number(columns = Importance, decimals = 1)\n\n# Create importance plot\ntree_importance |&gt;\n  mutate(Variable = fct_reorder(Variable, Importance)) |&gt;\n  ggplot(aes(x = Importance, y = Variable)) +\n  geom_col(fill = \"steelblue\") +\n  labs(\n    title = \"Which Features Best Predict Fraud?\",\n    x = \"Importance Score\",\n    y = NULL\n  )"
  },
  {
    "objectID": "posts/08-classification.html#business-impact-analysis",
    "href": "posts/08-classification.html#business-impact-analysis",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Business Impact Analysis",
    "text": "Business Impact Analysis\n\n# Calculate business metrics\nbusiness_impact &lt;- test_predictions |&gt;\n  mutate(\n    # Define risk levels based on probability\n    risk_level = case_when(\n      .pred_Fraudulent &gt;= 0.7 ~ \"High Risk\",\n      .pred_Fraudulent &gt;= 0.4 ~ \"Medium Risk\",\n      TRUE ~ \"Low Risk\"\n    )\n  ) |&gt;\n  summarize(\n    # Detection rates\n    total_fraud = sum(fraud == \"Fraudulent\"),\n    fraud_detected = sum(fraud == \"Fraudulent\" & .pred_class == \"Fraudulent\"),\n    detection_rate = fraud_detected / total_fraud,\n    \n    # False positive impact\n    false_positives = sum(fraud == \"Legitimate\" & .pred_class == \"Fraudulent\"),\n    false_positive_rate = false_positives / sum(fraud == \"Legitimate\"),\n    \n    # Workload analysis\n    high_risk_count = sum(risk_level == \"High Risk\"),\n    investigation_rate = high_risk_count / n()\n  )\n\n# Display business metrics\nbusiness_impact |&gt;\n  pivot_longer(everything(), names_to = \"Metric\", values_to = \"Value\") |&gt;\n  gt() |&gt;\n  tab_header(title = \"Business Impact Metrics\")"
  },
  {
    "objectID": "posts/08-classification.html#implementation-recommendations",
    "href": "posts/08-classification.html#implementation-recommendations",
    "title": "8: Classification Analysis for Fraud Detection",
    "section": "Implementation Recommendations",
    "text": "Implementation Recommendations\nBased on your analysis, complete these recommendations:\n\nModel Performance: The decision tree achieved _____% accuracy with _____% sensitivity (fraud detection rate).\nKey Fraud Indicators: The top three predictors of fraud were:\n\n_____: (Importance score: _____)\n_____: (Importance score: _____)\n\nInvestigation Strategy:\n\nFocus on transactions with fraud probability &gt; _____%\nThis would require investigating _____% of transactions\nExpected to catch _____% of actual fraud\n\nControl Improvements:\n\nStrengthen controls around _____ (highest importance variable)\nImplement automated flags for _____"
  },
  {
    "objectID": "posts/09_kpi_cfo.html",
    "href": "posts/09_kpi_cfo.html",
    "title": "9: KPI Dashboard for CFO",
    "section": "",
    "text": "Write a 2-3 sentence summary of the financial performance and key insights from your KPI dashboard. Complete this section after finishing the assignment."
  },
  {
    "objectID": "posts/09_kpi_cfo.html#executive-summary",
    "href": "posts/09_kpi_cfo.html#executive-summary",
    "title": "9: KPI Dashboard for CFO",
    "section": "",
    "text": "Write a 2-3 sentence summary of the financial performance and key insights from your KPI dashboard. Complete this section after finishing the assignment."
  },
  {
    "objectID": "posts/09_kpi_cfo.html#introduction",
    "href": "posts/09_kpi_cfo.html#introduction",
    "title": "9: KPI Dashboard for CFO",
    "section": "Introduction",
    "text": "Introduction\nAs an accounting professional creating executive dashboards, you need to build visualizations that communicate financial performance effectively to CFOs. KPI dashboards help executives:\n\nMonitor financial health at a glance\nTrack performance against targets\nIdentify trends and potential issues\nMake data-driven strategic decisions\n\nIn this blog post, you will:\n\nCreate professional KPI tables using gt\nBuild interactive financial visualizations\nAnalyze liquidity and profitability metrics\nDesign a comprehensive CFO dashboard"
  },
  {
    "objectID": "posts/09_kpi_cfo.html#setup-and-load-libraries",
    "href": "posts/09_kpi_cfo.html#setup-and-load-libraries",
    "title": "9: KPI Dashboard for CFO",
    "section": "Setup and Load Libraries",
    "text": "Setup and Load Libraries\n\nRequired Libraries\n\n# Load packages we need - matching the slides\nlibrary(tidyverse)     # For data manipulation\nlibrary(scales)        # For formatting numbers\nlibrary(gt)            # For creating elegant tables\nlibrary(plotly)        # For interactive plots\n\n# Set theme for consistent styling\ntheme_set(theme_minimal(base_size = 12))\n\n# Create custom color palette for financial data\nfin_colors &lt;- c(\n  positive = \"#2E7D32\",  # Green for positive values\n  negative = \"#C62828\",  # Red for negative values\n  neutral = \"#1976D2\",   # Blue for neutral values\n  posback = \"#C8E6C9\",   # Light green for background\n  negback = \"#FFCDD2\"    # Light red for background\n)\n\n\n\nLoad and Explore the Data\n\n# Load the financial data\nfinancial_data &lt;- read_rds(\"data/09-assignment-financial_data.rds\")\n\n# Display structure of the data\nglimpse(financial_data)\n\n# View summary statistics\nfinancial_data |&gt;\n  summary()"
  },
  {
    "objectID": "posts/09_kpi_cfo.html#initial-data-exploration",
    "href": "posts/09_kpi_cfo.html#initial-data-exploration",
    "title": "9: KPI Dashboard for CFO",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\n\nFinancial Performance Overview\n\n# Calculate summary statistics for key metrics\nperformance_summary &lt;- financial_data |&gt;\n  summarize(\n    months_of_data = n(),\n    avg_revenue = mean(_____),\n    revenue_growth = (last(_____) - first(_____)) / first(_____),\n    avg_gross_margin = mean(_____),\n    avg_operating_margin = mean(_____),\n    ending_cash = last(_____)\n  )\n\n# Display summary\nperformance_summary |&gt;\n  gt() |&gt;\n  fmt_currency(columns = c(_____, _____), decimals = 0) |&gt;\n  fmt_percent(columns = c(_____, _____, _____), decimals = 1) |&gt;\n  fmt_number(columns = months_of_data, decimals = 0)\n\n\n\nMonthly Trends Overview\n\n# Create a trend summary for the last 6 months\nrecent_trends &lt;- financial_data |&gt;\n  slice_tail(n = 6) |&gt;\n  select(date, revenue, operating_margin, cash_balance) |&gt;\n  gt() |&gt;\n  fmt_date(columns = date, date_style = \"yMMM\") |&gt;\n  fmt_currency(columns = c(_____, _____), decimals = 0) |&gt;\n  fmt_percent(columns = _____, decimals = 1) |&gt;\n  tab_header(\n    title = \"Recent Performance Trends\",\n    subtitle = \"Last 6 Months\"\n  )\n\nrecent_trends"
  },
  {
    "objectID": "posts/09_kpi_cfo.html#key-performance-indicators-table",
    "href": "posts/09_kpi_cfo.html#key-performance-indicators-table",
    "title": "9: KPI Dashboard for CFO",
    "section": "Key Performance Indicators Table",
    "text": "Key Performance Indicators Table\n\nCurrent vs Prior Month Comparison\n\n# Get current and prior month data\ncurrent_month &lt;- financial_data |&gt;\n  filter(date == _____(date))\n\nprior_month &lt;- financial_data |&gt;\n  filter(date == max(date) - _____(1))\n\n# Create KPI comparison with more metrics\nkpi_comparison &lt;- tribble(\n  ~Metric, ~Current, ~Prior, ~Change, ~Status,\n  \"Revenue\", current_month$_____, prior_month$_____, \n    (current_month$_____ - prior_month$_____) / prior_month$_____,\n    ifelse(current_month$_____ &gt; prior_month$_____, \"positive\", \"negative\"),\n  \n  \"Gross Margin\", current_month$_____, prior_month$_____,\n    current_month$_____ - prior_month$_____,\n    ifelse(current_month$_____ &gt; prior_month$_____, \"positive\", \"negative\"),\n  \n  \"Operating Margin\", current_month$_____, prior_month$_____,\n    current_month$_____ - prior_month$_____,\n    ifelse(current_month$_____ &gt; prior_month$_____, \"positive\", \"negative\"),\n  \n  \"Cash Balance\", current_month$_____, prior_month$_____,\n    (current_month$_____ - prior_month$_____) / prior_month$_____,\n    ifelse(current_month$_____ &gt; prior_month$_____, \"positive\", \"negative\"),\n    \n  \"Current Ratio\", current_month$_____, prior_month$_____,\n    current_month$_____ - prior_month$_____,\n    ifelse(current_month$_____ &gt; prior_month$_____, \"positive\", \"negative\")\n)\n\n# Format as professional table with gt\nkpi_comparison |&gt;\n  gt() |&gt;\n  # Format different types of metrics appropriately\n  fmt_currency(\n    columns = c(Current, Prior),\n    rows = Metric %in% c(\"Revenue\", \"Cash Balance\"),\n    decimals = 0\n  ) |&gt;\n  fmt_percent(\n    columns = c(Current, Prior),\n    rows = Metric %in% c(\"Gross Margin\", \"Operating Margin\"),\n    decimals = 1\n  ) |&gt;\n  fmt_number(\n    columns = c(Current, Prior),\n    rows = Metric == \"Current Ratio\",\n    decimals = 2\n  ) |&gt;\n  fmt_percent(\n    columns = Change,\n    rows = Metric %in% c(\"Revenue\", \"Cash Balance\"),\n    decimals = 1\n  ) |&gt;\n  fmt_number(\n    columns = Change,\n    rows = Metric %in% c(\"Gross Margin\", \"Operating Margin\", \"Current Ratio\"),\n    decimals = 2\n  ) |&gt;\n  cols_hide(columns = Status) |&gt;\n  # Add conditional formatting\n  tab_style(\n    style = cell_text(color = fin_colors[\"_____\"], weight = \"bold\"),\n    locations = cells_body(\n      columns = Change,\n      rows = Status == \"_____\"\n    )\n  ) |&gt;\n  tab_style(\n    style = cell_text(color = fin_colors[\"_____\"], weight = \"bold\"),\n    locations = cells_body(\n      columns = Change,\n      rows = Status == \"_____\"\n    )\n  ) |&gt;\n  # Add header\n  tab_header(\n    title = \"Monthly KPI Summary\",\n    subtitle = \"Key Financial Metrics - Month over Month\"\n  )"
  },
  {
    "objectID": "posts/09_kpi_cfo.html#liquidity-analysis",
    "href": "posts/09_kpi_cfo.html#liquidity-analysis",
    "title": "9: KPI Dashboard for CFO",
    "section": "Liquidity Analysis",
    "text": "Liquidity Analysis\n\nCalculate and Display Liquidity Ratios\n\n# Calculate liquidity metrics for the latest month\nliquidity_metrics &lt;- financial_data |&gt;\n  filter(date == max(date)) |&gt;\n  select(current_ratio, quick_ratio, cash_ratio) |&gt;\n  pivot_longer(everything(), names_to = \"ratio_type\", values_to = \"Value\") |&gt;\n  mutate(\n    Ratio = case_when(\n      ratio_type == \"current_ratio\" ~ \"Current Ratio\",\n      ratio_type == \"quick_ratio\" ~ \"Quick Ratio\", \n      ratio_type == \"cash_ratio\" ~ \"Cash Ratio\"\n    ),\n    Benchmark = c(2.0, 1.0, 0.5),  # Industry benchmarks\n    Status = ifelse(Value &gt;= Benchmark, \"_____\", \"_____\"),\n    Difference = Value - Benchmark\n  )\n\n# Create enhanced liquidity table\nliquidity_metrics |&gt;\n  select(Ratio, Value, Benchmark, Difference, Status) |&gt;\n  gt() |&gt;\n  fmt_number(\n    columns = c(Value, Benchmark, Difference),\n    decimals = 2\n  ) |&gt;\n  # Add conditional formatting for Status\n  tab_style(\n    style = cell_fill(color = fin_colors[\"_____\"]),\n    locations = cells_body(\n      columns = Status,\n      rows = Status == \"Healthy\"\n    )\n  ) |&gt;\n  tab_style(\n    style = cell_fill(color = fin_colors[\"_____\"]),\n    locations = cells_body(\n      columns = Status,\n      rows = Status == \"Warning\"\n    )\n  ) |&gt;\n  # Color code the difference\n  tab_style(\n    style = cell_text(color = fin_colors[\"positive\"]),\n    locations = cells_body(\n      columns = Difference,\n      rows = Difference &gt; 0\n    )\n  ) |&gt;\n  tab_style(\n    style = cell_text(color = fin_colors[\"negative\"]),\n    locations = cells_body(\n      columns = Difference,\n      rows = Difference &lt; 0\n    )\n  ) |&gt;\n  cols_label(\n    Ratio = \"Liquidity Metric\",\n    Value = \"Current\",\n    Benchmark = \"Target\",\n    Difference = \"+/-\",\n    Status = \"Status\"\n  ) |&gt;\n  tab_header(\n    title = \"Liquidity Analysis\",\n    subtitle = \"Current Month vs Industry Benchmarks\"\n  )"
  },
  {
    "objectID": "posts/09_kpi_cfo.html#financial-visualizations",
    "href": "posts/09_kpi_cfo.html#financial-visualizations",
    "title": "9: KPI Dashboard for CFO",
    "section": "Financial Visualizations",
    "text": "Financial Visualizations\n\nRevenue and Profitability Trends\n\n# Create revenue trend plot with profit overlay\nrevenue_profit_plot &lt;- financial_data |&gt;\n  ggplot(aes(x = date)) +\n  geom_col(aes(y = _____), fill = fin_colors[\"neutral\"], alpha = 0.7) + # revenue\n  geom_line(aes(y = _____), color = fin_colors[\"positive\"], size = 2) + # operating_profit\n  geom_point(aes(y = _____), color = fin_colors[\"positive\"], size = 3) + # operating_profit\n  scale_y_continuous(\n    labels = dollar_format(scale = 1e-6, suffix = \"M\")) +\n  scale_x_date(date_labels = \"%b %Y\") +\n  labs(\n    title = \"Revenue and Operating Profit Trends\",\n    subtitle = \"Monthly Performance Over Time\",\n    x = NULL,\n    y = NULL\n  ) \n\n# Convert to interactive\nggplotly(revenue_profit_plot) |&gt;\nlayout(\n    hovermode = \"x unified\"\n  )\n\n\n\nMargin Analysis\n\n# Create margin comparison over time\nmargin_data &lt;- financial_data |&gt;\n  select(date, gross_margin, operating_margin) |&gt;\n  _____(cols = -date, names_to = \"Metric\", values_to = \"Value\") |&gt;\n  mutate(\n    Metric = case_when(\n      Metric == \"gross_margin\" ~ \"Gross Margin\",\n      Metric == \"operating_margin\" ~ \"Operating Margin\"\n    )\n  )\n\n# Create the plot\nmargin_plot &lt;- margin_data |&gt;\n  ggplot(aes(x = date, y = Value, color = Metric)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(size = 2.5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  _____(labels = percent_format()) +\n  scale_x_date(date_labels = \"%b %Y\") +\n  scale_color_manual(values = c(\n    \"Gross Margin\" = fin_colors[[\"positive\"]],\n    \"Operating Margin\" = fin_colors[[\"neutral\"]]\n  )) +\n  _____(\n    title = \"Profitability Margins Trend\",\n    subtitle = \"Gross vs Operating Margins\",\n    x = NULL,\n    y = NULL,\n    color = NULL\n  ) \n\n# Make interactive\nggplotly(_____) |&gt;\n  layout(\n    hovermode = \"x unified\"\n  )"
  },
  {
    "objectID": "posts/09_kpi_cfo.html#working-capital-analysis",
    "href": "posts/09_kpi_cfo.html#working-capital-analysis",
    "title": "9: KPI Dashboard for CFO",
    "section": "Working Capital Analysis",
    "text": "Working Capital Analysis\n\nDays Sales Outstanding and Days Payable Outstanding\n\n# Create working capital efficiency metrics plot\nwc_metrics &lt;- financial_data |&gt;\n  select(date, days_sales_outstanding, days_payable_outstanding) |&gt;\n  pivot_longer(cols = -date, names_to = \"Metric\", values_to = \"Days\") |&gt;\n  _____(\n    Metric = case_when(\n      Metric == \"days_sales_outstanding\" ~ \"Days Sales Outstanding\",\n      Metric == \"days_payable_outstanding\" ~ \"Days Payable Outstanding\"\n    )\n  )\n\n# Create the plot\nwc_plot &lt;- wc_metrics |&gt;\n  _____(aes(x = date, y = Days, fill = Metric)) +\n  geom_col(position = \"dodge\") +\n  scale_x_date(date_labels = \"%b %Y\") +\n  scale_fill_manual(values = c(\n    \"Days Sales Outstanding\" = fin_colors[[\"negative\"]],\n    \"Days Payable Outstanding\" = fin_colors[[\"positive\"]]\n  )) +\n  labs(\n    title = \"Working Capital Efficiency\",\n    x = NULL,\n    y = \"Days\",\n    fill = NULL\n  ) \n\n# Convert to interactive\nggplotly(wc_plot) |&gt;\n  layout(hovermode = \"x unified\")\n\n\n\nCash Balance and Cash Flow Analysis\n\n# Calculate monthly cash flow (simplified)\ncash_flow_data &lt;- financial_data |&gt;\n  mutate(\n    monthly_cash_change = cash_balance - lag(cash_balance),\n    cash_from_operations = operating_profit + \n      (lag(accounts_receivable) - accounts_receivable) - \n      (lag(accounts_payable) - accounts_payable)\n  ) |&gt;\n  filter(!is.na(monthly_cash_change))\n\n# Create cash balance trend with cash flow\ncash_plot &lt;- cash_flow_data |&gt;\n  ggplot(aes(x = date)) +\n  geom_area(aes(y = _____), fill = fin_colors[\"neutral\"], alpha = 0.3) +\n  geom_line(aes(y = _____), color = fin_colors[\"neutral\"], size = 1.5) +\n  geom_col(aes(y = _____), \n           fill = ifelse(cash_flow_data$_____ &gt; 0, \n                        fin_colors[\"positive\"], \n                        fin_colors[\"negative\"]),\n           alpha = 0.7) +\n  scale_y_continuous(labels = dollar_format(scale = 1e-3, suffix = \"K\")) +\n  scale_x_date(date_labels = \"%b %Y\") +\n  labs(\n    title = \"Cash Position and Monthly Cash Flow\",\n    subtitle = \"Balance (Line) and Monthly Change (Bars)\",\n    x = NULL,\n    y = NULL\n  )\n\n# Convert to interactive\nggplotly(cash_plot) |&gt;\n  layout(hovermode = \"x unified\")"
  },
  {
    "objectID": "posts/09_kpi_cfo.html#executive-summary-dashboard",
    "href": "posts/09_kpi_cfo.html#executive-summary-dashboard",
    "title": "9: KPI Dashboard for CFO",
    "section": "Executive Summary Dashboard",
    "text": "Executive Summary Dashboard\n\nComprehensive Performance Summary\n\n# Create executive summary for last 6 months\nexec_summary &lt;- financial_data |&gt;\n  slice_tail(n = 6) |&gt;\n  arrange(date) |&gt;\n  mutate(\n    month_name = month(date, label = TRUE, abbr = FALSE)\n  )\n\n\n# Create comprehensive summary table\nexec_summary |&gt;\n  select(month_name, revenue, gross_margin, operating_margin, \n         cash_balance, current_ratio, revenue_growth_rate) |&gt;\n  gt() |&gt;\n  # Format monetary columns\n  fmt_currency(\n    columns = c(_____, _____),\n    decimals = 0\n  ) |&gt;\n  # Format percentage columns\n  fmt_percent(\n    columns = c(_____, _____, _____),\n    decimals = 1\n  ) |&gt;\n  # Format ratio\n  fmt_number(\n    columns = _____,\n    decimals = 2\n  ) |&gt;\n  # Add column labels\n  cols_label(\n    month_name = \"Month\",\n    revenue = \"Revenue\",\n    gross_margin = \"Gross Margin\",\n    operating_margin = \"Op Margin\",\n    cash_balance = \"Cash\",\n    current_ratio = \"Current Ratio\",\n    revenue_growth_rate = \"YoY Growth\"\n  ) |&gt;\n  # Add header\n  tab_header(\n    title = \"Executive Performance Summary (2026)\",\n    subtitle = \"Six-Month Financial Dashboard\"\n  ) |&gt;\n  # Highlight most recent month\n  tab_style(\n    style = list(\n      cell_fill(color = \"#E3F2FD\"),\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_body(rows = _____)\n  ) \n\n\n\nKey Metrics Scorecard\n\n# Create a metrics scorecard for the latest month\nlatest_metrics &lt;- financial_data |&gt;\n  filter(date == max(date))\n\n# Define targets and create scorecard\nscorecard &lt;- tribble(\n  ~Category, ~Metric, ~Value, ~Target, ~Performance,\n  \"Growth\", \"Monthly Revenue\", latest_metrics$revenue, 850000, \n    ifelse(latest_metrics$revenue &gt;= 850000, \"Above Target\", \"Below Target\"),\n  \n  \"Profitability\", \"Operating Margin\", latest_metrics$operating_margin, 0.15,\n    ifelse(latest_metrics$operating_margin &gt;= 0.15, \"Above Target\", \"Below Target\"),\n  \n  \"Liquidity\", \"Current Ratio\", latest_metrics$current_ratio, 2.0,\n    ifelse(latest_metrics$current_ratio &gt;= 2.0, \"Above Target\", \"Below Target\"),\n  \n  \"Efficiency\", \"Days Sales Outstanding\", latest_metrics$days_sales_outstanding, 50,\n    ifelse(latest_metrics$days_sales_outstanding &lt;= 50, \"Above Target\", \"Below Target\"),\n  \n  \"Cash Management\", \"Cash Balance\", latest_metrics$cash_balance, 1000000,\n    ifelse(latest_metrics$cash_balance &gt;= 1000000, \"Above Target\", \"Below Target\")\n)\n\n# Create scorecard table\nscorecard |&gt;\n  gt() |&gt;\n  # Format values based on metric type\n  fmt_currency(\n    columns = Value,\n    rows = Metric %in% c(\"Monthly Revenue\", \"Cash Balance\"),\n    decimals = 0\n  ) |&gt;\n  fmt_percent(\n    columns = Value,\n    rows = Metric == \"Operating Margin\",\n    decimals = 1\n  ) |&gt;\n  fmt_number(\n    columns = Value,\n    rows = Metric %in% c(\"Current Ratio\", \"Days Sales Outstanding\"),\n    decimals = 1\n  ) |&gt;\n  # Format targets similarly\n  fmt_currency(\n    columns = Target,\n    rows = Metric %in% c(\"Monthly Revenue\", \"Cash Balance\"),\n    decimals = 0\n  ) |&gt;\n  fmt_percent(\n    columns = Target,\n    rows = Metric == \"Operating Margin\",\n    decimals = 1\n  ) |&gt;\n  fmt_number(\n    columns = Target,\n    rows = Metric %in% c(\"Current Ratio\", \"Days Sales Outstanding\"),\n    decimals = 1\n  ) |&gt;\n  # Apply conditional formatting\n  tab_style(\n    style = list(\n      cell_fill(color = fin_colors[\"posback\"]),\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_body(\n      columns = Performance,\n      rows = Performance == \"Above Target\"\n    )\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_fill(color = fin_colors[\"negback\"]),\n      cell_text(weight = \"bold\")\n    ),\n    locations = cells_body(\n      columns = Performance,\n      rows = Performance == \"Below Target\"\n    )\n  ) |&gt;\n  tab_header(\n    title = \"Performance Scorecard\",\n    subtitle = \"Current Month vs Targets\"\n  )"
  },
  {
    "objectID": "posts/09_kpi_cfo.html#key-insights-and-recommendations",
    "href": "posts/09_kpi_cfo.html#key-insights-and-recommendations",
    "title": "9: KPI Dashboard for CFO",
    "section": "Key Insights and Recommendations",
    "text": "Key Insights and Recommendations\nBased on your dashboard analysis, complete these insights:\n\nRevenue Performance: Revenue has grown from $_____ to $_____ over the 24-month period, representing _____% growth.\nProfitability Trends:\n\nGross margin has averaged _____% and is currently at _____%\nOperating margin has improved from _____% to _____%, showing _____\n\nLiquidity Position:\n\nCurrent ratio of _____ is above/below industry benchmark of 2.0\nCash position has grown/declined from $_____ to $_____\n\nWorking Capital Management:\n\nDays Sales Outstanding averages _____ days\nCash conversion cycle is _____ days (DSO - DPO)\n\nRecommendations for CFO:\n\nFocus area 1: _____\nFocus area 2: _____\nKey metric to monitor: _____"
  }
]